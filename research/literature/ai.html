<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.4">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Sustainable AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="ai_files/libs/clipboard/clipboard.min.js"></script>
<script src="ai_files/libs/quarto-html/quarto.js"></script>
<script src="ai_files/libs/quarto-html/popper.min.js"></script>
<script src="ai_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="ai_files/libs/quarto-html/anchor.min.js"></script>
<link href="ai_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ai_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ai_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="ai_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="ai_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Sustainable AI</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="ai-fying-user-interfaces-for-sustainability" class="level1">
<h1>AI-fying User Interfaces (for Sustainability)</h1>
<p>How can AI interfaces enable/help/encourage sustainability?</p>
<section id="human-patterns" class="level2">
<h2 class="anchored" data-anchor-id="human-patterns">Human Patterns</h2>
<p>The fact that AI systems work so well is proof that we live in a measurable world. The world is filled with structures: nature, cultures, languages, human interactions - all form intricate patterns. Computer systems are increasingly capable in their ability copy these patterns into computer models - known as machine learning. As of 2023, 97 zettabytes (and growing) of data was created in the world per year <span class="citation" data-cites="soundaryajayaramanHowBigBig2023">(Soundarya Jayaraman, 2023)</span>. Big data is a basic requirement for training AIs, enabling learning from the structures of the world with increasing accuracy. Representations of the real world in digital models enable humans to ask questions about the real-world structures and to manipulate them to create synthetic experiments that may match the real world (if the model is accurate enough). This can be used for generating human-sounding language and realistic images, finding mechanisms for novel medicines as well as understanding the fundamental functioning of life on its deep physical and chemical level <span class="citation" data-cites="nopriorsInceptiveCEOJakob2023">(No Priors: AI, Machine Learning, Tech, &amp; Startups, 2023)</span>.</p>
<p>In essence, Human Patterns Enable AIs. Already ninety years ago <span class="citation" data-cites="mccullochLogicalCalculusIdeas1943">(McCulloch &amp; Pitts, 1943)</span> proposed the first mathematical model of a neural network inspired by the human brain. Alan Turing’s Test for Machine Intelligence followed in 1950. Turing’s initial idea was to design a game of imitation to test human-computer interaction using text messages between a human and 2 other participants, one of which was a human, and the other - a computer. The question was, if the human was simultaneously speaking to another human and a machine, could the messages from the machine be clearly distinguished or would they resemble a human being so much, that the person asking questions would be deceived, unable to realize which one is the human and which one is the machine? <span class="citation" data-cites="turingCOMPUTINGMACHINERYINTELLIGENCE1950">(Turing, 1950)</span>.</p>
<blockquote class="blockquote">
<p>Alan Turing: <em>“I believe that in about fifty years’ time it will be possible to program computers, with a storage capacity of about 10<sup>9</sup>, to make them play the imitation game so well that an average interrogator will not have more than 70 percent chance of making the right identification after five minutes of questioning. … I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.”</em> - from <span class="citation" data-cites="stanfordencyclopediaofphilosophyTuringTest2021">(Stanford Encyclopedia of Philosophy, 2021)</span></p>
</blockquote>
<p>By the 2010s AI models became capable enough to beat humans in games of Go and Chess, yet they did not yet pass the Turing test. AI use was limited to specific tasks. While over the years, the field of AI had seen a long process of incremental improvements, developing increasingly advanced models of decision-making, it took an <strong><em>increase in computing power</em></strong> and an approach called <strong><em>deep learning</em></strong>, a variation of <strong><em>machine learning (1980s),</em></strong> largely modeled after the <strong><em>neural networks</em></strong> of the biological (human) brain, returning to the idea of <strong><em>biomimicry</em></strong>, inspired by nature, building a machine to resemble the connections between neurons, but digitally, on layers much deeper than attempted before.</p>
<p>“Generating structured data from unstructured inputs is one of the core use cases for AI” <span class="citation" data-cites="pokrassIntroducingStructuredOutputs2024">Pokrass (2024)</span></p>
<section id="reinforcement-learning-with-human-feedback-rlhf" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning-with-human-feedback-rlhf"><strong>Reinforcement Learning with Human Feedback (RLHF)</strong></h3>
<p>Combining deep learning and reinforcement learning with human feedback (RLHF) enabled to achieve levels of intelligence high enough to beat the Turing test <span class="citation" data-cites="karamankeChatGPTArchitectBerkeley2022 christianoMyResearchMethodology2021 christianoDeepReinforcementLearning2017">(Kara Manke, 2022; Christiano, 2021; Christiano et al., 2017)</span>. OpenAI co-founder John Schulman describes RLHF simply: <em>“the models are just trained to produce a single message that gets high approval from a human reader”</em> <span class="citation" data-cites="karamankeChatGPTArchitectBerkeley2022">(Kara Manke, 2022)</span>.</p>
<p>The nature-inspired approach was successful. Innovations such as <em>back-propagation</em> for reducing errors through updating model weights and <em>transformers</em> for tracking relationships in sequential data (for example in sentences), enabled AI models to became increasingly capable <span class="citation" data-cites="vaswaniAttentionAllYou2017 merrittWhatTransformerModel2022">(Vaswani et al., 2017; Merritt, 2022)</span>. Generative Adversarial Networks*** (GAN), (<strong>ADD CITATION, 2016</strong>), and <strong><em>Large Language Models (</em>ADD CITATION<em>, 2018)</em></strong>, enabled increasingly generalized models, capable of more complex tasks, such as language generation. One of the leading scientists in this field of research, Geoffrey Hinton, had attempted back-propagation already in the 1980s and reminiscents how <em>“the only reason neural networks didn’t work in the 1980s was because we didn’t have have enough data and we didn’t have enough computing power”</em> <span class="citation" data-cites="cbsmorningsFullInterviewGodfather2023">(CBS Mornings, 2023)</span>. <span class="citation" data-cites="epochaiDataNotableAI2024">(Epoch AI, 2024)</span> reports the growth in computing power and the evolution of more than 800 AI models since the 1950s. Very simply, more data and more computing power means more intelligent models.</p>
<div id="13c16fe6" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>growth_compute_chart()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ai_files/figure-html/cell-3-output-1.png" width="1136" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>How do transformers work? Illustration <span class="citation" data-cites="alammarIllustratedTransformer2018">Alammar (2018)</span></li>
</ul>
<p>By the 2020s, AI-based models became a mainstay in medical research, drug development, patient care <span class="citation" data-cites="LEITE20212515 holzingerAILifeTrends2023a">(Leite et al., 2021; Holzinger et al., 2023)</span>, quickly finding potential vaccine candidates during the COVID19 pandemic <span class="citation" data-cites="ZAFAR2022249">(Zafar &amp; Ahamed, 2022)</span>, self-driving vehicles, including cars, delivery robots, drones in the sea and air, as well as AI-based assistants. The existence of AI models has wide implications for all human activities from personal to professional. The founder of the largest chimp-maker NVIDIA calls upon all countries do develop their own AI-models which would encode their local knowledge, culture, and language to make sure these are accurately captured <span class="citation" data-cites="worldgovernmentssummitConversationFounderNVIDIA2024">(World Governments Summit, 2024)</span>.</p>
<p>OpenAI has researched a wide range of approaches towards artificial general intelligence (AGI), work which has led to advances in large language models<span class="citation" data-cites="ilyasutskeverIlyaSutskeverAI2018 aifrontiersIlyaSutskeverAI2018">(Ilya Sutskever, 2018; AI Frontiers, 2018)</span>. In 2020 OpenAI released a LLM called GPT-3 trained on 570 GB of text <span class="citation" data-cites="alextamkinHowLargeLanguage2021">(Alex Tamkin &amp; Deep Ganguli, 2021)</span> which was adept in text-generation. <span class="citation" data-cites="Singer2022MakeAVideoTG">(Singer et al., 2022)</span> describes how collecting billions of images with descriptive data (for example the descriptive <em>alt</em> text which accompanies images on websites) enabled researchers to train AI models such as <strong><em>stable diffusion</em></strong> for image-generation based on human-language. These training make use of <strong><em>Deep Learning</em></strong>, a layered approach to AI training, where increasing depth of the computer model captures minute details of the world. Much is still to be understood about how deep learning works; the fractal structure of deep learning can only be called mysterious <span class="citation" data-cites="sohl-dicksteinBoundaryNeuralNetwork2024">(Sohl-Dickstein, 2024)</span>.</p>
</section>
<section id="the-idiot-savant" class="level3">
<h3 class="anchored" data-anchor-id="the-idiot-savant">The Idiot Savant</h3>
<p>Hinton likes to call AI an <em>idiot savant</em>: someone with exceptional aptitude yet serious mental disorder <span class="citation" data-cites="cbsmorningsFullInterviewGodfather2023">(CBS Mornings, 2023)</span>. Large AI models don’t understand the world like humans do. Their responses are predictions based on their training data and complex statistics. Indeed, the comparison is apt, as the AI field now offers jobs for <em>AI psychologists (ADD CITATION)</em>, whose role is to figure out what exactly is happening inside the ‘AI brain’. Understading the insides of AI models trained of massive amounts of data is important because they are <em>foundational</em>, enabling a holistic approach to learning, combining many disciplines using languages, instead of the reductionist way we as human think because of our limitations <span class="citation" data-cites="capinstituteGettingRealArtificial2023">(CapInstitute, 2023)</span>.</p>
<p>Standford “thorough account of the opportunities and risks of foundation models” <span class="citation" data-cites="bommasaniOpportunitiesRisksFoundation2021">(Bommasani et al., 2021)</span>.</p>
<p>Foundation models in turn enabled <em>generative AIs</em>, a class of models which are able to generate many types of <em>tokens<strong>,</strong></em> such as text, speech, audio <span class="citation" data-cites="sanroman2023fromdi kreukAudioGenTextuallyGuided2022">(San Roman et al., 2023; Kreuk et al., 2022)</span>, music <span class="citation" data-cites="copetSimpleControllableMusic2023 metaaiAudioCraftSimpleOnestop2023">(Copet et al., 2023; Meta AI, 2023)</span>, video, and even complex structures such 3D models and DNA structures, in any language it’s trained on. The advent of generative AIs was a revolution in human-computer interaction as AI models became increasingly capable of producing human-like content which is hard to distinguish from actual human creations. This power comes with <em>increased need for responsibility</em>, drawing growing interest in fields like <em>AI ethics</em> and <em>AI explainability.</em> Generative has a potential for misuse, as humans are increasingly confused by what is computer-generated and what is human-created, unable to separate one from the other with certainty.</p>
<p>The technological leap is great enough for people to start calling it a start of a new era.<span class="citation" data-cites="nobleFifthIndustrialRevolution2022">(Noble et al., 2022)</span> proposes AI has reached a stage of development marking beginning of the <em>5th industrial revolution</em>, a time of collaboration between humans and AI. Widespread Internet of Things (IoT) sensor networks that gather data analyzed by AI algorithms, integrates computing even deeper into the fabric of daily human existence. Several terms of different origin but considerable overlap describe this phenomenon, including <em>Pervasive Computing (PC)</em> <span class="citation" data-cites="rogersFourPhasesPervasive2022">(Rogers, 2022)</span> and <em>Ubiquitous Computing</em>. Similar concepts are <em>Ambient Computing</em>, which focuses more on the invisibility of technology, fading into the background, without us, humans, even noticing it, and <em>Calm Technology</em>, which highlights how technology respects humans and our limited attention spans, and doesn’t call attention to itself. In all cases, AI is integral part of our everyday life, inside everything and everywhere. Today AI is not an academic concept but a mainstream reality, affecting our daily lives everywhere, even when we don’t notice it.</p>
</section>
<section id="human-in-the-loop-hitl" class="level3">
<h3 class="anchored" data-anchor-id="human-in-the-loop-hitl"><strong>Human-in-the-Loop (HITL)</strong></h3>
<p>AI responses are probabilistic and need some function for ranking response quality. Achieving higher percentage or correct responses requires oversight which can come in the form of human feedback (human-in-the-loop) - or by using other AIs systems which are deemed to be already well-aligned (termed Constitutional AI by Anthropic) <span class="citation" data-cites="baileyAIEducation2023 baiConstitutionalAIHarmlessness2022">(Bailey, 2023; Bai et al., 2022)</span>. Less powerful AIs areFor example META used LLAMA 2 for aligning LLAMA 3.</p>
<p>One approach to reduce the issues with AI is to introduce some function for human feedback and oversight to automated systems. Human involvement can take the form of interventions from the AI-developer themselves as well as from the end-users of the AI system.</p>
<p>There are many examples of combination of AI and human, also known as <em>“human-in-the-loop”,</em> used for fields as diverse as training computer vision algorithms for self-driving cars and detection of disinformation in social media posts <span class="citation" data-cites="wuHumanintheLoopAIEnhancing2023 bonet-joverSemiautomaticAnnotationMethodology2023">(Wu et al., 2023; Bonet-Jover et al., 2023)</span>.</p>
<p>Also known as Human-based computation or human-aided artificial intelligence <span class="citation" data-cites="Shahaf2007TowardsAT muhlhoffHumanaidedArtificialIntelligence2019">(Shahaf &amp; Amir, 2007; Mühlhoff, 2019)</span></p>
<ul>
<li>Stanford Institute for Human-Centered Artificial Intelligence <span class="citation" data-cites="gewangHumansLoopDesign2019">Ge Wang (2019)</span></li>
</ul>
<table class="caption-top table">
<caption>Examples of human-in-the-loop apps</caption>
<colgroup>
<col style="width: 26%">
<col style="width: 26%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>App</th>
<th>Category</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Welltory</td>
<td>Health</td>
<td>Health data analysis</td>
</tr>
<tr class="even">
<td>Wellue</td>
<td>Health</td>
<td>Heart arrhythmia detection</td>
</tr>
<tr class="odd">
<td>QALY</td>
<td>Health</td>
<td>Heart arrhythmia detection</td>
</tr>
<tr class="even">
<td>Starship Robots</td>
<td>Delivery</td>
<td>May ask for human help when crossing a difficult road or other confusing situation</td>
</tr>
</tbody>
</table>
</section>
<section id="algorithmic-experiences-before-non-deterministic-systems" class="level3">
<h3 class="anchored" data-anchor-id="algorithmic-experiences-before-non-deterministic-systems">Algorithmic Experiences Before Non-Deterministic Systems</h3>
<p>Even before AIs, as a user of social media, one may be accustomed to interacting with the feed algorithms that provide a personalized <em>algorithmic experience</em>. Algorithms are more deterministic than AI, meaning they would produce more predictable output in comparison AI models. Nonetheless, there are many reports about effects these algorithms have on human psychology <strong>(ADD CITATION)</strong>. Design is increasingly relevant to algorithms, and more specifically to algorithms that affect user experience and user interfaces. <strong><em>When the design is concerned with the ethical, environmental, socioeconomic, resource-saving, and participatory aspects of human-machine interactions and aims to affect technology in a more human direction, it can hope to create an experience designed for sustainability.</em></strong></p>
<p><span class="citation" data-cites="lorenzoDaisyGinsbergImagines2015">Lorenzo, Lorenzo &amp; Lorenzo (2015)</span> underlines the role of design beyond <em>designing</em> as a tool for envisioning; in her words, <em>“design can set agendas and not necessarily be in service, but be used to find ways to explore our world and how we want it to be”</em>. Practitioners of Participatory Design (PD) have for decades advocated for designers to become more activist through <strong><em>action research</em></strong>. This means to influencing outcomes, not only being a passive observer of phenomena as a researcher, or only focusing on usability as a designer, without taking into account the wider context.</p>
<p><span class="citation" data-cites="shenoiParticipatoryDesignFuture2018">Shenoi (2018)</span> argues inviting domain expertise into the discussion while having a sustainable design process enables designers to design for experiences where they are not a domain expert; this applies to highly technical fields, such as medicine, education, governance, and in our case here - finance and sustainability -, while building respectful dialogue through participatory design. After many years of political outcry (ADD CITATION), social media platforms such Facebook and Twitter have begun to shed more light on how these algorithms work, in some cases releasing the source code (<span class="citation" data-cites="nickcleggHowAIInfluences2023">Nick Clegg (2023)</span>; <span class="citation" data-cites="twitterTwitterRecommendationAlgorithm2023">Twitter (2023)</span>).</p>
<p>AI systems may make use of several algorithms within one larger model. It follows that AI Explainability requires <em><strong>Algorithmic Transparency</strong>.</em></p>
<p>The content on the platform can be more important than the interface. Applications with a similar UI depend on the community as well as the content and how the content is shown to the user.</p>
</section>
<section id="transitioning-to-complexity" class="level3">
<h3 class="anchored" data-anchor-id="transitioning-to-complexity">Transitioning to Complexity</h3>
<p>AIs are non-deterministic, which requires a new set of consideration when designing AI.</p>
</section>
<section id="being-responsible-explainable-and-safe" class="level3">
<h3 class="anchored" data-anchor-id="being-responsible-explainable-and-safe">Being Responsible, Explainable, and Safe</h3>
<p>The problems of opaqueness creates the field of explainable AI.</p>
<p><em>“As humans we tend to fear what we don’t understand”</em> is a common sentiment which has been confirmed psychology <span class="citation" data-cites="allportNaturePrejudice1979">(Allport, 1979)</span>. Current AI-models are opaque ’<em>black boxes’</em>, where it’s difficult to pin-point exactly why a certain decision was made or how a certain expression was reached, not unlike inside the human brain. This line of thought leads me to the idea of <strong><em>AI psychologists,</em></strong> who might figure out the <strong><em>thought patterns</em></strong> inside the model. Research in AI-explainability (XAI in literature) is on the lookout for ways to create more <strong><em>transparency and credibility</em></strong> in AI systems, which could lead to building trust in AI systems and would form the foundations for <strong><em>AI acceptance</em></strong>.</p>
<p>Red-teaming means pushing the limits of LLMs, trying to get them to produce outputs that are racist, false, or otherwise unhelpful.</p>
<p>There’s an increasing number of tools for LLM evaluation:</p>
<ul>
<li><p>“Evaluate and Track LLM Applications, Explainability for Neural Networks” <span class="citation" data-cites="trueraTruLens2023 leinoInfluenceDirectedExplanationsDeep2018">(TruEra, 2023; Leino et al., 2018)</span></p></li>
<li><p>“evaluate your Retrieval Augmented Generation (RAG) pipelines, Metrics-Driven Development” <span class="citation" data-cites="ragasMetricsDrivenDevelopment2023">Ragas (2023)</span></p></li>
<li><p>LangSmith “developer platform for every step of the LLM-powered application lifecycle, whether you’re building with LangChain or not. Debug, collaborate, test, and monitor your LLM applications.” <span class="citation" data-cites="langchainDynamicFewshotExamples2024">LangChain (2024)</span></p></li>
<li><p><span class="citation" data-cites="tristangreeneConfusedReplikaAI2022">Tristan Greene (2022)</span>: when the quality of AI responses becomes good enough, people begin to get confused.</p></li>
</ul>
<p><span class="citation" data-cites="bowmanEightThingsKnow2023">Bowman (2023)</span> says steering Large Language Models is unreliable; even experts don’t fully understand the inner workings of the models. Work towards improving both <strong><em>AI steerability</em></strong> and <strong><em>AI alignment</em></strong> (doing what humans expect) is ongoing. <span class="citation" data-cites="liangHolisticEvaluationLanguage2022">Liang et al. (2022)</span> believes there’s early evidence it’s possible to assess the quality of LLM output transparently. <span class="citation" data-cites="CABITZA2023118888">Cabitza et al. (2023)</span> proposes a framework for quality criteria and explainability of AI-expressions. <span class="citation" data-cites="khosraviExplainableArtificialIntelligence2022">Khosravi et al. (2022)</span> proposes a framework for AI explainability, focused squarely on education. <span class="citation" data-cites="holzingerMultimodalCausabilityGraph2021">Holzinger et al. (2021)</span> highlights possible approaches to implementing transparency and explainability in AI models. While AI outperforms humans on many tasks, humans are experts in multi-modal thinking, bridging diverse fields.</p>
<ul>
<li><p>Bigger models aren’t necessarily better; rather models need human feedback to improve the quality of responses <span class="citation" data-cites="ouyangTrainingLanguageModels2022">Ouyang et al. (2022)</span></p></li>
<li><p>The user experience (UX) of AI is a topic under active development by all the largest online platforms. The general public is familiar with the most famous AI helpers, ChatGPT, Apple’s Siri, Amazon’s Alexa, Microsoft’s Cortana, Google’s Assistant, Alibaba’s Genie, Xiaomi’s Xiao Ai, and many others. For general, everyday tasks, such as asking factual questions, controlling home devices, playing media, making orders, and navigating the smart city.</p></li>
</ul>
<p>The AI Credibility Heuristic: A Systematic Model explains how… similar to Daniel Kahneman’s book “Thinking, Fast and Slow”.</p>
<ul>
<li><p><span class="citation" data-cites="slackAturaProcess2021">Slack (2021)</span></p></li>
<li><p><span class="citation" data-cites="shinHowUsersInteract2020">Shin (2020)</span>: “user experience and usability of algorithms by focusing on users’ cognitive process to understand how qualities/features are received and transformed into experiences and interaction”</p></li>
<li><p><span class="citation" data-cites="zerilliHowTransparencyModulates2022">Zerilli, Bhatt &amp; Weller (2022)</span> focuses on human factors and ergonomics and argues that transparency should be task-specific.</p></li>
<li><p><span class="citation" data-cites="holbrookHumanCenteredMachineLearning2018">Holbrook (2018)</span>: To reduce errors which only humans can detect, and provide a way to stop automation from going in the wrong direction, it’s important to focus on making users feel in control of the technology.</p></li>
<li><p><span class="citation" data-cites="ZHANG2023107536">Zhang et al. (2023)</span> found humans are more likely to trust an AI teammate if they are not deceived by it’s identity. It’s better for collaboration to make it clear, one is talking to a machine. One step towards trust is the explainability of AI-systems.</p></li>
</ul>
<p>Personal AI Assistants to date have we created by large tech companies. <strong>Open-Source AI-models open up the avenue for smaller companies and even individuals for creating many new AI-assistants.</strong></p>
<ul>
<li>An explosion of personal AI assistants powered by GPT models.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>App</th>
<th>Features</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>socratic.org</td>
<td>Study buddy</td>
</tr>
<tr class="even">
<td>youper.ai</td>
<td>Mental health helper</td>
</tr>
<tr class="odd">
<td>fireflies.ai</td>
<td>Video call transcription</td>
</tr>
<tr class="even">
<td>murf.ai</td>
<td>Voice generator</td>
</tr>
</tbody>
</table>
<p>Responsible AI Seeks to Mitigate Generative AIs’ Known Issues.</p>
<p>Given the widespread use of AI and its increasing power of foundational models, it’s important these systems are created in a safe and responsible manner. While there have been calls to pause the development of large AI experiments <span class="citation" data-cites="futureoflifeinstitutePauseGiantAI2023">(Future of Life Institute, 2023)</span> so the world could catch up, this is unlikely to happen. There are several problems with the current generation of LLMs from OpenAI, Microsoft, Google, Nvidia, and others.</p>
<p>Anthropic responsible <em>scaling policy</em> <span class="citation" data-cites="AnthropicResponsibleScaling2023">(Anon, 2023a)</span></p>
<p>METR – Model Evaluation &amp; Threat Research incubated in the Alignment Research Center <span class="citation" data-cites="METR2023">(Anon, 2023d)</span>.</p>
<p><span class="citation" data-cites="christianoMyViewsDoom2023">(Christiano, 2023)</span> believes there are plenty of ways for bad outcomes (existential risk) even without extinction risk.</p>
<table class="caption-top table">
<caption>Table summarizing some problems with contemporary AIs.</caption>
<colgroup>
<col style="width: 36%">
<col style="width: 63%">
</colgroup>
<tbody>
<tr class="odd">
<td>Problem</td>
<td>Description</td>
</tr>
<tr class="even">
<td>Monolithicity</td>
<td>LLMs are massive monolithic models requiring large amounts of computing power for training to offer <strong><em>multi-modal</em></strong> <strong><em>capabilities</em></strong> across diverse domains of knowledge, making training such models possible for very few companies. <span class="citation" data-cites="liuPrismerVisionLanguageModel2023">Liu et al. (2023)</span> proposes future AI models may instead consist of a number networked domain-specific models to increase efficiency and thus become more scalable.</td>
</tr>
<tr class="odd">
<td>Opaqueness</td>
<td>LLMs are opaque, making it difficult to explain why a certain prediction was made by the AI model. One visible expression of this problem are <em><strong>hallucinations</strong>,</em> the language models are able to generate text that is confident and eloquent yet entirely wrong. Jack Krawczyk, the product lead for Google’s Bard (now renamed to Gemini): “Bard and ChatGPT are large language models, not knowledge models. They are great at generating human-sounding text, they are not good at ensuring their text is fact-based. Why do we think the big first application should be Search, which at its heart is about finding true information?”</td>
</tr>
<tr class="even">
<td>Biases and Prejudices</td>
<td>AI bias is well-documented and a hard problem to solve <span class="citation" data-cites="liangGPTDetectorsAre2023">(Liang et al., 2023)</span>. <strong>Humans don’t necessarily correct mistakes made by computers and may instead become “partners in crime”</strong> <span class="citation" data-cites="krugelAlgorithmsPartnersCrime2023">(Krügel, Ostermaier &amp; Uhl, 2023)</span>. People are prone to bias and prejudice. It’s a part of the human psyche. Human brains are limited and actively avoid learning to save energy. These same biases are likely to appear in LLM outputs as they are trained on human-produced content. Unless there is active work to try to counter and eliminate these biases from LLM output, they will appear frequently.</td>
</tr>
<tr class="odd">
<td>Missing Data</td>
<td>LLMs have been pre-trained on massive amounts of public data, which gives them the ability for for reasoning and generating in a human-like way, yet they are missing specific private data, which needs to be ingested to augment LLMs ability to respond to questions on niche topics <span class="citation" data-cites="Liu_LlamaIndex_2022">(Liu, 2022)</span>.</td>
</tr>
<tr class="even">
<td>Data Contamination</td>
<td>Concerns with the math ability of LLMs. “performance actually reflects dataset contamination, where data closely resembling benchmark questions leaks into the training data, instead of true reasoning ability” <span class="citation" data-cites="zhangCarefulExaminationLarge2024">Zhang et al. (2024)</span></td>
</tr>
<tr class="odd">
<td>Lack of Legislation</td>
<td><span class="citation" data-cites="anderljungFrontierAIRegulation2023">Anderljung et al. (2023)</span> OpenAI proposes we need to proactively work on common standards and legislation to ensure AI safety. It’s difficult to come up with clear legislation; the U.K. government organized the first AI safety summit in 2023 <span class="citation" data-cites="browneBritainHostWorld2023">Browne (2023)</span>.</td>
</tr>
</tbody>
</table>
<p>In 2024, OpenAI released its “Model Spec” to define clearly their approach to AI safety with the stated intention to provide clear guidelines for the RLHF approach. <span class="citation" data-cites="openaiIntroducingModelSpec2024">OpenAI (2024c)</span></p>
<ul>
<li><p>OpenAI does not yet understand how the internal of an neural network work; they are developing tools to represent NNs concepts for humans <span class="citation" data-cites="openaiExtractingConceptsGPT42024 gaoScalingEvaluatingSparse2024">(OpenAI, 2024a; Gao et al., 2024)</span>.</p></li>
<li><p>AI co-founder launches AI Safety Superalignment <span class="citation" data-cites="janleikeIntroducingSuperalignment2023">(Jan Leike &amp; Ilya Sutskever, 2023)</span>.</p></li>
<li><p>OECD defines AI incident terms <span class="citation" data-cites="DefiningAIIncidents2024">Anon (2024b)</span></p></li>
<li><p>Foundation data-sets such as LAION-5B <span class="citation" data-cites="romainbeaumontLAION5BNEWERA2022 schuhmannLAION5BOpenLargescale2022">(Romain Beaumont, 2022; Schuhmann et al., 2022)</span></p></li>
<li><p>Knowing Machines</p></li>
</ul>
<p><em>AI acceptance</em> is incumbent on traits that are increasingly human-like and would make a human be acceptable: credibility, trustworthiness, reliability, dependability, integrity, character, etc.</p>
</section>
<section id="mapping-the-evolution-of-models-and-their-emerging-abilities" class="level3">
<h3 class="anchored" data-anchor-id="mapping-the-evolution-of-models-and-their-emerging-abilities">Mapping the Evolution of Models and their Emerging Abilities</h3>
<p>The debate between Open Source v.s. Closed-Source AI is ongoing. Historically open-source has been useful for finding bugs in code as more pairs of eyes are looking at the code and someone may see a problem the programmers have not noticed. Proponents of closed-source development however worry about the dangers or releasing such powerful technology openly and the possibility of bad actors such as terrorists, hackers, violent governments using LLMs for malice. The question whether closed-sourced or open-sourced development will be lead to more AI safety is one of the large debates in the AI industry. In any case, open or closed-sourced, real-world usage of LLMs may demonstrate the limitations and edge-cases of AI. Hackathons such as <span class="citation" data-cites="peteWeHostedEmergencychatgpthackathon2023">(Pete, 2023)</span> help come up with new use-cases and disprove some potential ideas.</p>
<table class="caption-top table">
<caption>Summary of 7 years of rapid AI model innovation since the first LLM was publicly made available in 2018 <span class="citation" data-cites="brown2020language tamkin2021 alvarezGenerateChatbotTraining2021 hinesOpenAIFilesTrademark2023 metaIntroducingMetaLlama2024">(Brown et al., 2020; Tamkin et al., 2021; Alvarez, 2021; Hines, 2023a; META, 2024)</span>.</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>AI Model</th>
<th>Released</th>
<th>Company</th>
<th>License</th>
<th>Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GPT-1</td>
<td>2018</td>
<td>OpenAI</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>GTP-2</td>
<td>2019</td>
<td>OpenAI</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>Turing-NLG</td>
<td>2020</td>
<td>Microsoft</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>GPT-3</td>
<td>2020</td>
<td>OpenAI</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>GPT-3.5</td>
<td>2022</td>
<td>OpenAI</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>GPT-4</td>
<td>2023</td>
<td>OpenAI</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>AlexaTM</td>
<td>2022</td>
<td>Amazon</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>NeMo</td>
<td>2022</td>
<td>NVIDIA</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>PaLM</td>
<td>2022</td>
<td>Google</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>LaMDA</td>
<td>2022</td>
<td>Google</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>GLaM</td>
<td>2022</td>
<td>Google</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>BLOOM</td>
<td>2022</td>
<td>Hugging Face</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>Falcon</td>
<td>2023</td>
<td>Technology Innovation Institute</td>
<td>Open Source</td>
<td>U.A.E.</td>
</tr>
<tr class="even">
<td>Tongyi</td>
<td>2023</td>
<td>Alibaba</td>
<td>Proprietary</td>
<td>China</td>
</tr>
<tr class="odd">
<td>Vicuna</td>
<td>2023</td>
<td>Sapling</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>Wu Dao 3</td>
<td>2023</td>
<td>BAAI</td>
<td>Open Source</td>
<td>China</td>
</tr>
<tr class="odd">
<td>LLAMA 2</td>
<td>2023</td>
<td>META</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>PaLM-2</td>
<td>2023</td>
<td>Google</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>Claude 3</td>
<td>2024</td>
<td>Anthropic</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>Mistral Large</td>
<td>2024</td>
<td>Mistral</td>
<td>Proprietary</td>
<td>France</td>
</tr>
<tr class="odd">
<td>Gemini 1.5</td>
<td>2024</td>
<td>Google</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>LLAMA 3</td>
<td>2024</td>
<td>META</td>
<td>Open Source</td>
<td>U.S.</td>
</tr>
<tr class="odd">
<td>AFM</td>
<td>2024</td>
<td>Apple</td>
<td>Proprietary</td>
<td>U.S.</td>
</tr>
<tr class="even">
<td>Viking 7B</td>
<td>2024</td>
<td>Silo</td>
<td>Open Source</td>
<td>Finland</td>
</tr>
<tr class="odd">
<td>GPT-5</td>
<td>202?</td>
<td>OpenAI</td>
<td>Unknown; trademark registered</td>
<td>U.S.</td>
</tr>
</tbody>
</table>
<div id="2d3ae62e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>models_chart()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ai_files/figure-html/cell-4-output-1.png" width="1175" height="839" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The proliferation of different models enables comparisons of performance based on several metrics from accuracy of responses to standardized tests such as GMAT usually taken my humans to reasoning about less well defined problem spaces. <span class="citation" data-cites="chiang2024chatbot lmsys.orgGPT4TurboHasJust2024">(Chiang et al., 2024; lmsys.org, 2024)</span> open-source AI-leaderboard project has collected over 500 thousand human-ranking of outputs from 82 large-language models, evaluating reasoning capabilities, which currently rate GPT-4 and Claude 3 Opus as the top-performers. <span class="citation" data-cites="zellersHellaSwagCanMachine2019">(Zellers et al., 2019)</span>’s HellaSwag paper is also accompanied by a leaderboard website (still being updated after publication) listing AI model performance most recent entry April 16, 2024).</p>
<ul>
<li><p>Scaling laws of LLMs <span class="citation" data-cites="kaplanScalingLawsNeural2020">Kaplan et al. (2020)</span></p></li>
<li><p>English is over-represented in current models so Finnish <span class="citation" data-cites="SiloAINew2024">Anon (2024d)</span> focuses on Nordic languages.</p></li>
</ul>
<p>Metacognition – Claude 3 is the first model capable of it?, like the zero waste workshop training guidebook.</p>
<ul>
<li>complex decision-making systems. Apple’s Foundation Language Models (AFM) is split into a smaller on-device model and a server-side model. <span class="citation" data-cites="dangAppleAIUnderstanding2024">Dang (2024)</span></li>
</ul>
<p>Metacognition defined as <em>knowing about knowing</em> <span class="citation" data-cites="metcalfeMetacognitionKnowingKnowing1994">(Anon, 1994)</span> or “<em>keeping track of your own learning”</em> <span class="citation" data-cites="zerowasteeuropeZeroWasteHandbook2022">(Zero Waste Europe et al., 2022)</span>.</p>
<ul>
<li><p><span class="citation" data-cites="dwarkeshpatelMarkZuckerbergLlama2024">Dwarkesh Patel (2024)</span> META open-sourced the largest language model (70 billion parameters) which with performance rivaling several of the proprietary models.</p></li>
<li><p>Image-generation is now fast it’s possible to create images in real-time while the user is typing <span class="citation" data-cites="dwarkeshpatelMarkZuckerbergLlama2024">Dwarkesh Patel (2024)</span></p></li>
<li><p>Measuring Massive Multitask Language Understanding (MMLU) <span class="citation" data-cites="hendrycksMeasuringMassiveMultitask2020">Hendrycks et al. (2020)</span>.</p></li>
</ul>
<p>Another important metric is Retrieval Augmented Generation (RAG) performace. Generative AI applications retrieve data from unstructured external sources in order to augment LLMs existing knowledge with current information <span class="citation" data-cites="lengLongContextRAG2024">(Leng et al., Mon, 08/12/2024 - 19:46)</span>.</p>
<div id="e0eed399" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>models_rag_performance()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ai_files/figure-html/cell-5-output-1.png" width="821" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="companions" class="level2">
<h2 class="anchored" data-anchor-id="companions">Companions</h2>
<section id="acceptance-affective-computing-enables-human-friendly-machines" class="level3">
<h3 class="anchored" data-anchor-id="acceptance-affective-computing-enables-human-friendly-machines">Acceptance: Affective Computing Enables Human-Friendly Machines</h3>
<p>Rosalind Picard is the founder of the <em>affective computing</em> field. Her pioneering work aims to make computers more human-friendly. Because of the conversational nature of LLMs, they are very useful for affective computing, an approach to recognizing human emotions with machines and providing users experiences that take human emotion into account <span class="citation" data-cites="picardAffectiveComputing1997">(Picard, 1997)</span>.</p>
<p>Just as LLMs, affective computing relies on input data. It’s not an overstatement to say data from all the processes around us will define the future of computing as <span class="citation" data-cites="hiittvWojciechSzpankowskiEmerging2021">HIITTV (2021b)</span> puts it. In the early examples, electrodermal activity of the skin and heart-rate variance data were used to detect the emotional state and stress level of the user <span class="citation" data-cites="zangronizElectrodermalActivitySensor2017 velmovitskyUsingAppleWatch2022">(Zangróniz et al., 2017; Velmovitsky et al., 2022)</span>. This technology has since become mainstream in products such as Fitbit and the Apple Watch among many others.</p>
<p>Affective Design emerged from affective computing with a focus on understanding user emotions to design UI/UX to which elicits specific emotional responses <span class="citation" data-cites="Reynolds2001DesigningFA">(Reynolds, 2001)</span>.</p>
<p>Apple Watch features Fall Detection which I’ve experienced personally. Riding my bicycle to the NCKU library I slipped and landed on my stomach on the pavement. Watch immediately asked me: “It looks like you’ve taken a hard fall” and offered an option to call the ambulance. Fortunately I was OK but if I did need assistance, this AI algorithm delivered contextual help which could save my health.</p>
<p>On the output side, <span class="citation" data-cites="lvCutenessIrresistibleImpact2022">Lv et al. (2022)</span> studies the effect of <strong><em>cuteness</em></strong> of AI apps on users and found high perceived cuteness correlated with higher willingness to use the apps, especially for emotional tasks.</p>
<ul>
<li><span class="citation" data-cites="liuMachineGazeOnline2021">(Liu &amp; Wei, 2021)</span> suggests higher <em>algorithmic transparency may inhibit anthropomorphismI</em>; people are less likely to attribute humanness to an AI if they understand how the system works.</li>
<li><span class="citation" data-cites="tedxTechEmotionsRoz2011">TEDx Talks (2011)</span></li>
<li><span class="citation" data-cites="lexfridmanRosalindPicardAffective2019">Lex Fridman (2019)</span></li>
<li><span class="citation" data-cites="hiittvRosalindPicardAdventures2021">HIITTV (2021a)</span></li>
<li><span class="citation" data-cites="bwhcnocRosalindPicard4th2023">BWH CNOC (2023)</span></li>
<li><span class="citation" data-cites="singularityuniversityEngineeringEmotionAI2023">Singularity University (2023)</span></li>
</ul>
<p>Since the first mainframe computers with rudimentary computers able to respond with text messages, humans have been drawn to discussing their private lives with a machine that doesn’t judge you like a human could. A famous anecdote is about the lab assistant of the Joseph Weizenbaum MIT ELIZA project in the mid-1960s (1996), who would dedicate extended time to talking to the machine in private. The machine was called DOCTOR and emulated a Rogerian psychotherapist, person-centered therapy developed by Carl Rogers, from the core idea that positive psychological functioning is a inherently human motivation <span class="citation" data-cites="bassettComputationalTherapeuticExploring2019 rogersWayBeing1995">(Bassett, 2019; Rogers, 1995)</span>.</p>
<ul>
<li>ELIZA is an early examples of a language model</li>
</ul>
<p>Natural language generation exists since Eliza</p>
</section>
<section id="acceptance-conversations-are-the-starting-point-of-a-relationship" class="level3">
<h3 class="anchored" data-anchor-id="acceptance-conversations-are-the-starting-point-of-a-relationship">Acceptance: Conversations Are the Starting Point of a Relationship</h3>
<p>High quality conversations are somewhat magical in that they can establish trust and build rapport which humans.</p>
<p><span class="citation" data-cites="CELINO2020102410">(Celino &amp; Re Calegari, 2020)</span> found in testing chatbots for survey interfaces that “[c]onversational survey lead to an improved response data quality.”</p>
<p>Conversational AI</p>
<ul>
<li><span class="citation" data-cites="baileyAIEducation2023">Bailey (2023)</span> believes people are used to search engines and it will take a little bit time to get familiar with talking to a computer in natural language. NVIDIA founder Jensen Huang makes the idea exceedingly clear, saying <em>“Everyone is a programmer. Now, you just have to say something to the computer”</em> <span class="citation" data-cites="leswingNvidiaRevealsNew2023">Leswing (2023)</span>.</li>
</ul>
<p>There are noticeable differences in the quality of the LLM output, which increases with model size. <span class="citation" data-cites="levesqueWinograd2012">Levesque, Davis &amp; Morgenstern (2012)</span> developed the <em>Winograd Schema Challenge</em>, looking to improve on the Turing test, by requiring the AI to display an understanding of language and context. The test consists of a story and a question, which has a different meaning as the context changes: “The trophy would not fit in the brown suitcase because it was too big” - what does the <em>it</em> refer to? Humans are able to understand this from context while a computer models would fail. Even GPT-3 still failed the test, but later LLMs have been able to solve this test correctly (90% accuracy) <span class="citation" data-cites="kocijanDefeatWinogradSchema2022">Kocijan et al. (2022)</span>. This is to say AI is in constant development and improving it’s ability to make sense of language.</p>
<p><em>ChatGPT</em> is the first <em>user interface (UI)</em> built on top of GPT-4 by OpenAI and is able to communicate in a human-like way - using first-person, making coherent sentences that sound plausible, and even - confident and convincing. <span class="citation" data-cites="wangEconomicCaseGenerative2023">Wang (2023)</span> ChatGPT reached 1 million users in 5 days and 6 months after launch has 230 million monthly active users. While it was the first, competing offers from Google (Gemini), Anthrophic (Claude), Meta (Llama) and others quickly followed starting a race for best performance across specific tasks including standardized tests from math to science to general knowledge and reasoning abilities.</p>
<p>OpenAI provides AI-as-a-service through its <em>application programming interfaces (APIs),</em> allowing 3rd party developers to build custom UIs to serve the specific needs of their customer. For example Snapchat has created a <em>virtual friend</em> called “My AI” who lives inside the chat section of the Snapchat app and helps people write faster with predictive text completion and answering questions. The APIs make state-of-the-art AI models easy to use without needing much technical knowledge. Teams at AI-hackathons have produced interfaces for problems as diverse as humanitarian crises communication, briefing generation, code-completion, and many others. For instance, <span class="citation" data-cites="unleashSebastianAi2017">(Unleash, 2017)</span> used BJ Fogg’s <em>tiny habits model</em> to develop a sustainability-focused AI assistant at the Danish hackathon series Unleash, to encourage behavioral changes towards maintaining an aspirational lifestyle, nudged by a chatbot buddy.</p>
<p>ChatGPT makes it possible to <em>evaluate AI models</em> just by talking, i.e.&nbsp;having conversations with the machine and judging the output with some sort of structured content analysis tools. <span class="citation" data-cites="oconnorOpenArtificialIntelligence2023">Cahan &amp; Treutlein (2023)</span> have conversations about science with AI. <span class="citation" data-cites="pavlikCollaboratingChatGPTConsidering2023">Pavlik (2023)</span> and <span class="citation" data-cites="brenta.andersWhyChatGPTSuch2022">Brent A. Anders (2022/2023)</span> report on AI in education. <span class="citation" data-cites="kechtQuantifyingChatbotsAbility2023">(Kecht et al., 2023)</span>] suggests AI is even capable of learning business processes.</p>
<ul>
<li><span class="citation" data-cites="fuLearningConversationalAI2022">Fu et al. (2022)</span> Learning towards conversational AI: Survey</li>
</ul>
</section>
<section id="acceptance-natural-multi-modal-interactions-enhance-the-humanity-of-artificial-systems" class="level3">
<h3 class="anchored" data-anchor-id="acceptance-natural-multi-modal-interactions-enhance-the-humanity-of-artificial-systems">Acceptance: <strong>Natural</strong> Multi-Modal <strong>Interactions</strong> Enhance the Humanity of Artificial Systems</h3>
<p>Humans are multi-modal creatures by birth. To varied ability, we speak, see, listen using our biological bodies. AIs are becoming multi-modal by design to be able to match all the human modes of communication.</p>
<p>By early 2024, widely available LLMs front-ends such as Gemini, Claude and ChatGPT have all released basic features for multi-modal communication. In practice, this means combination several AI models within the same interface. For example, on the input side, one model is used for human speech or image recognition which are transcribed into tokens that can be ingested into an LLM. On the output side, the LLM can generate instructions which are fed into an image / audio generation model or even computer code which can be ran on a virtual machine and then the output displayed inside the conversation.</p>
<p>The quality of LLM output depends on the quality of the provided prompt. <span class="citation" data-cites="zhouLargeLanguageModels2022">Zhou et al. (2022)</span> reports creating an “Automatic Prompt Engineer” which automatically generates instructions that outperform the baseline output quality by using another model in the AI pipeline in front of the LLM to enhance the human input with language that is known to produce better quality. This approach however is a moving target as foundational models keep changing rapidly and the baseline might differ from today to 6 months later.</p>
<p>Multimodal model development is also ongoing. In the case of Google’s Gemini 1.5 Pro, one model is able to handle several types of prompts from text to images. Multimodal prompting however requires larger context windows, as of writing, limited to 1 million tokens in a private version allows combining text and images in the question directed to the AI, used to reason in examples such as a 44-minute Buster Keaton silent film or Apollo 11 launch transcript (404 pages) <span class="citation" data-cites="googleMultimodalPrompting44minute2024">Google (2024)</span>.</p>
<p>Literature delves into human-AI interactions on almost human-like level discussing what kind of roles can the AIs take. <span class="citation" data-cites="seeberMachinesTeammatesResearch2020">(Seeber et al., 2020)</span> proposes a future research agenda for regarding <strong><em>AI assistants as teammates</em></strong> rather than just tools and the implications of such mindset shift.</p>
<p>From Assistance to Collaboration</p>
<p>It’s not only what role the AI takes but how that affects the human. As humans have ample experience relating to other humans and as such the approach towards an assistants vs a teammate will vary. One researcher in this field <span class="citation" data-cites="karpusAlgorithmExploitationHumans2021">Karpus et al. (2021)</span> is concerned with humans treating AI badly and coins the term <strong>“<em>algorithm exploitation”</em></strong><em>.</em></p>
<ul>
<li>From assistant -&gt; teammate -&gt; companion -&gt; friend The best help for anxiety is a friend. AIs are able to assume different roles based on user requirements and usage context. This makes AI-generated content flexible and malleable.</li>
</ul>
<p>Just as humans, AIs are continuously learning. <span class="citation" data-cites="ramchurnTrustworthyHumanAIPartnerships2021">Ramchurn, Stein &amp; Jennings (2021)</span> discusses positive feedback loops in continually learning AI systems which adapt to human needs.</p>
<p><em>Context of Use,</em> Where is the AI used? <span class="citation" data-cites="schoonderwoerdHumancenteredXAIDeveloping2021">(Schoonderwoerd et al., 2021)</span> focuses on human-centered design of AI-apps and multi-modal information display. It’s important to understand the domain where the AI is deployed in order to develop explanations. However, in the real world, how feasible is it to have control over the domain? <span class="citation" data-cites="calistoIntroductionHumancentricAI2021">Calisto et al. (2021)</span> discusses <strong>multi-modal AI-assistant</strong> for breast cancer classification.</p>
</section>
<section id="interfaces-speech-makes-computers-feel-real" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-speech-makes-computers-feel-real">Interfaces: Speech Makes Computers Feel Real</h3>
<p>Voice has a visceral effect on the human psyche; since birth we recognize the voice of our mother. The voice of a loved one has a special effect. Voice is a integral part of the human experience. Machines that can use voice in an effective way are closer to representing and affecting human emotions.</p>
<p>Voice assistants such as Apple’s Siri and Amazon’s Alexa are well-known examples of AI technology in the world. Amazon’s Rohit Prasad thinks it can do so much more, “Alexa is not just an AI assistant – it’s a trusted advisor and a companion” <span class="citation" data-cites="prasadHowWillAlexa2022">(Prasad, 2022)</span>.</p>
<ul>
<li>LLMs combined with voice provide a unnerving user experience <span class="citation" data-cites="ethanmollick2023">Ethan Mollick [@emollick] (2023)</span></li>
<li>Ethical issues: Voice assistants need to continuously record human speech and process it in data centers in the cloud.</li>
<li>Siri, Cortana, Google Assistant, Alexa, Tencent Dingdang, Baidu Xiaodu, Alibaba AliGenie all rely on voice only.</li>
<li><span class="citation" data-cites="szczukaHowChildrenAcquire2022">Szczuka et al. (2022)</span> provides guidelines for Voice AI and kids</li>
<li><span class="citation" data-cites="casperkesselsGuidelinesDesigningInCar2022">Casper Kessels (2022a)</span>: “Guidelines for Designing an In-Car Voice Assistant”</li>
<li><span class="citation" data-cites="casperkesselsVoiceInteractionSolution2022">Casper Kessels (2022b)</span>: “Is Voice Interaction a Solution to Driver Distraction?”</li>
<li><span class="citation" data-cites="tangSemanticReconstructionContinuous2022">Tang et al. (2022)</span> reports new findings enable computers to reconstruct language from fMRI readings. - Focus on voice education?</li>
</ul>
<p>Some research suggests that voice UI accompanied by a <em>physical embodied system</em> is the preffered by users in comparison with voice-only UI <span class="citation" data-cites="CELINO2020102410">(Celino &amp; Re Calegari, 2020)</span>. This suggests adding an avatar to the AI design may be worthwhile.</p>
<p>There’s evidence across disciplines about the usefulness of AI assistants:</p>
<ul>
<li><span class="citation" data-cites="SERBAN20202849">(Şerban &amp; Todericiu, 2020)</span> suggests using the Alexa AI assistant in <em>education</em> during the pandemic, supported students and teachers ‘human-like’ presence. Standford research: “humans expect computers to be like humans or places”</li>
</ul>
</section>
<section id="interfaces-generative-uis-enable-flexibility-of-use" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-generative-uis-enable-flexibility-of-use">Interfaces: <strong>Generative UIs Enable Flexibility of Use</strong></h3>
<p>Artificial intelligence user experience (AI UX)</p>
<p>The promise of <em>Generative User Interfaces</em> (GenUI) is to dynamically provide an interface appropriate for the particular user and context.</p>
<p>Data-Driven Design Enables Generative User Interfaces (GenUI)</p>
<p>influences UI design patterns <span class="citation" data-cites="joyceRiseGenerativeAIdriven2024">Joyce (2024)</span></p>
<p>Generative AIs Enable New UI Interactions</p>
<p>The advances in the capabilities of LLMs makes it possible to achieve <strong><em>user experience (UX) which previously was science fiction</em></strong>.</p>
<ul>
<li>Towards Useful Personal Assistants</li>
</ul>
<p>The history of <em>intelligent interfaces</em> is long <span class="citation" data-cites="kobetzDecodingFutureEvolution2023">(Kobetz, 2023)</span></p>
<p>There’s wide literature available describing human-AI interactions across varied scientific disciplines. While the fields of application are diverse, some key lessons can be transferred horizontally across fields of knowledge.</p>
<table class="caption-top table">
<caption>A very small illustration of generative AI usage across disparate fields of human life.</caption>
<colgroup>
<col style="width: 36%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th>Field of Usage</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Shipping</td>
<td><span class="citation" data-cites="veitchSystematicReviewHumanAI2022">Veitch &amp; Andreas Alsos (2022)</span> highlights the active role of humans in Human-AI interaction is autonomous self-navigating ship systems.</td>
</tr>
<tr class="even">
<td>Data Summarizaton</td>
<td>AI is great at summarizing and analyzing data <span class="citation" data-cites="petersGoogleChromeWill2023 tuWhatShouldData2023">(Peters, 2023; Tu et al., 2023)</span></td>
</tr>
<tr class="odd">
<td>Childcare</td>
<td>Generate personalized bedtime stories</td>
</tr>
<tr class="even">
<td>Design Tools</td>
<td><span class="citation" data-cites="DavidHoangHow2024">Anon (2024a)</span></td>
</tr>
</tbody>
</table>
<ul>
<li><p><span class="citation" data-cites="cromptonDecisionpointdilemmaAnotherProblem2021">Crompton (2021)</span> highlights AI as decision-support for humans while differentiating between <strong><em>intended</em></strong> and <strong><em>unintended</em></strong> influence on human decisions.</p></li>
<li><p><span class="citation" data-cites="chengInvestigationTrustAIenabled2022">Cheng et al. (2022)</span> describes AI-based support systems for collaboration and team-work.</p></li>
<li><p><strong>Effective Accelerationism (often shortened to E\acc) boils down to the idea that “</strong>the potential for negative outcomes shouldn’t deter rapid advancement”</p></li>
<li><p>effects of unemployment on mental health. <span class="citation" data-cites="dewEffectsUnemploymentMental1991">Dew, Penkower &amp; Bromet (1991)</span>; <span class="citation" data-cites="Susskind2017AMO">Susskind (2017)</span>; <span class="citation" data-cites="antonkorinekScenarioPlanningAGI2023">Anton Korinek (2023)</span></p></li>
</ul>
<p>There are many ways to structure design theory. For the purposes of this AI-focused research, I will begin from Generative UI.</p>
<p>structure: data-driven design, generative UI</p>
<p>AI is able to predict what kind of UI would the user need right now, based on the data and context.</p>
<ul>
<li><p>Replit, a startup known for allowing user build apps in the web browser, released Openv0, a framework of AI-generated UI components <span class="citation" data-cites="replitReplitOpenv0OpenSource2023">(Replit, 2023)</span>. <em>“Components are the foundation upon which user interfaces (UI) are built, and generative AI is unlocking component creation for front-end developers, transforming a once arduous process, and aiding them in swiftly transitioning from idea to working components.”</em></p></li>
<li><p>Vercel introduced an open-source prototype UI-generator called V0 which used large language models (LLMs) to create code for web pages based on text prompts <span class="citation" data-cites="vercelIntroducingV0Generative2023">(Vercel, 2023)</span>. Other similar tools quickly following including Galileo AI, Uizard AutoDesigner and Visily <span class="citation" data-cites="WhoBenefitsMost2024">(Anon, 2024e)</span>.</p></li>
<li><p>In 2014, the eminent journal <em>Information Sciences</em> decided to dedicate a special section to AI-generated software to call attention to this tectonic shift in software development <span class="citation" data-cites="reformatSpecialSectionApplications2014">(Reformat, 2014)</span>.</p></li>
<li><p>As machines become more capable, machines will eventually be capable of producing machines.</p></li>
<li><p>Generative UIs are largely invented in practice, based on user data analysis and experimentation, rather than being built in theory. Kelly Dern, a Senior Product Designer at Google lead a workshop in early 2024 on <em>GenUI for product inclusion</em> aiming to create <strong><em>“<strong>more accessible and inclusive [UIs for] users of all backgrounds</strong>”.</em></strong></p></li>
<li><p><span class="citation" data-cites="GenerativeUIDesign2023">(Anon, 2023c)</span> gives an overview of the history of generative AI design tools going back in time until 2012 when <span class="citation" data-cites="troianoGeneticAlgorithmsSupporting2014">(Troiano &amp; Birtolo, 2014)</span> proposed genetic algorithms for UI design.</p></li>
<li><p><span class="citation" data-cites="fletcherGenerativeUIDownfall2023">(Fletcher, 2023)</span> and <span class="citation" data-cites="joeblairGenerativeUINew2024">(Joe Blair, 2024)</span> are worried UIs are becoming average; that is more and more similar towards the lowest common denominator. We can generate better ones that are based on user data and would be truly personalized.</p></li>
<li><p><span class="citation" data-cites="nielsenAccessibilityHasFailed2024">(Nielsen, 2024a)</span> recounts how 30 years of work towards usability has largely failed - computers are still not accessible enough (<strong><em>“difficult, slow, and unpleasant”</em></strong>) - and has hope Generative UI could offer a chance to provide levels of accessibility humans could not.</p></li>
<li><p><span class="citation" data-cites="matteosciortinoGenerativeUIHow2024">(Matteo Sciortino, 2024)</span> coins the phrase RTAG UIs <em>“real-time automatically-generated UI interfaces”</em> mainly drawing from the example of how his Netflix interface looks different from that of his sisters because of their dissimilar usage patterns.</p></li>
<li><p><span class="citation" data-cites="NielsenIdeasGenerative2024">(Anon, 2024c)</span> Meanwhile is very critical because for the following reasons:</p></li>
<li><p><span class="citation" data-cites="feifeiliuLiuFeiFeiPromptControlsGenAI">(Feifei Liu 刘菲菲, n.d.)</span> ChatGPT is using buttons to explain context.</p></li>
<li><p><span class="citation" data-cites="nielsenInformationScentHow2024">Nielsen (2024b)</span> information scent from Information Foraging theory <span class="citation" data-cites="pirolliInformationForaging1999">(Pirolli &amp; Card, 1999)</span>.</p></li>
</ul>
<table class="caption-top table">
<caption>Criticism of Generative UI by <span class="citation" data-cites="NielsenIdeasGenerative2024">(Anon, 2024c)</span>.</caption>
<colgroup>
<col style="width: 28%">
<col style="width: 71%">
</colgroup>
<thead>
<tr class="header">
<th>Problem</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Low predictability</td>
<td>Does personalization mean the UI keeps changing?</td>
</tr>
<tr class="even">
<td>High carbon cost</td>
<td>AI-based personalization is computation-intensive</td>
</tr>
<tr class="odd">
<td>Surveillance</td>
<td>Personalization needs large-scale data capture</td>
</tr>
</tbody>
</table>
<p>What is the user interface of the green transformation?</p>
<ul>
<li><span class="citation" data-cites="katemoranGenerativeUIOutcomeOriented2024">Kate Moran &amp; Sarah Gibbons (2024)</span> “highly personalized, tailor-made interfaces that suit the needs of each individual” “Outcome-Oriented Design”</li>
</ul>
<p><span class="citation" data-cites="mckeoughMcKinseyDesignLaunches2018">McKeough (2018)</span> business consultancies have begun to recognize the importance of design to business. They advise their corporate clients to bring user experience design to the core of their business operations.</p>
<p>There’s a number of user interface design patterns that have provide successful across a range of social media apps. Such <em>user experience / user interface</em> (UX/UI) patterns are copied from one app to another, to the extent that the largest apps share a similar look and feature set. Common UX/UI parts include the Feed and Stories. By using common UI parts from social media users have an easier time to accept the innovative parts. add Viz charts. Avatars are increasingly common and new generations are used to talking to computers.</p>
<table class="caption-top table">
<caption>Common Social Media UI Parts</caption>
<thead>
<tr class="header">
<th>Feature</th>
<th>Examples</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Feed</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Post</td>
<td>Apple App Store</td>
<td></td>
</tr>
<tr class="odd">
<td>Stories</td>
<td>IG, FB, WhatsApp, SnapChat, TikTok</td>
<td></td>
</tr>
<tr class="even">
<td>Comment</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Reactions</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>There are also more philosophical approaches to <strong><em>Interface Studies:</em></strong> <span class="citation" data-cites="davidhoangCreatingInterfaceStudies2022">David Hoang (2022)</span>, the head of product design at Webflow, suggests taking cues from art studies to <strong><em>isolate the core problem</em></strong>: <em>“An art study is any action done with the intention of learning about the subject you want to draw”</em>. As a former art student, Hoang looks at an interface as <em>“a piece of design is an artwork with function”</em>.</p>
<p>Indeed, art can be a way to see new paths forward, practicing “<em>fictioning</em>” to deal with problematic legacies: <span class="citation" data-cites="Review2023Helsinki2023">Anon (2023h)</span></p>
</section>
<section id="acceptance-artificial-empathy-also-builds-trust" class="level3">
<h3 class="anchored" data-anchor-id="acceptance-artificial-empathy-also-builds-trust">Acceptance: Artificial Empathy Also Builds Trust</h3>
<p>Today’s machines are much more capable so it’s not a surprise humans would like to talk to them. One example is <strong><em>AI Friend</em></strong> is Replika, a computer model trained to be your companion in daily life. <span class="citation" data-cites="jiangChatbotEmergencyExist2022">(Jiang, Zhang &amp; Pian, 2022)</span> describes how Replika users in China using in 5 main ways, all of which rely on empathy. The company’s CEO insists it’s not trying to replace human relationship but to create an entirely new relationship category with the AI companion; there’s value for the users in more realistic avatars, integrating the experience further into users’ daily lives through various activities and interactions <span class="citation" data-cites="patelReplikaCEOEugenia2024">(Patel, 2024)</span>.</p>
<table class="caption-top table">
<caption>Replika AI users approach to interacting with the AI friend from <span class="citation" data-cites="jiangChatbotEmergencyExist2022">Jiang, Zhang &amp; Pian (2022)</span>.</caption>
<thead>
<tr class="header">
<th>How humans express empathy towards the Replika AI companion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Companion buddy</td>
</tr>
<tr class="even">
<td>Responsive diary</td>
</tr>
<tr class="odd">
<td>Emotion-handling program</td>
</tr>
<tr class="even">
<td>Electronic pet</td>
</tr>
<tr class="odd">
<td>Tool for venting</td>
</tr>
</tbody>
</table>
<ul>
<li>Google is developing an AI assistant for giving life advice <span class="citation" data-cites="goswamiGoogleReportedlyBuilding2023">Goswami (2023)</span>.</li>
<li>GPT-4 is able to solve difficult task in chemistry with natural-language instructions <span class="citation" data-cites="whiteFutureChemistryLanguage2023">White (2023)</span></li>
<li>Emojis are a part of natural language <span class="citation" data-cites="tayWhyScienceNeeds2023">Tay (2023)</span></li>
</ul>
<p>Jakob Nielsen notes two recent studies suggesting human deem AI-generated responses more empathetic than human responses, at times by a significant marring; however telling users the response is AI-generated reduces the perceived empathy <span class="citation" data-cites="nielsenUXRoundupAI2024 ayersComparingPhysicianArtificial2023 yinAICanHelp2024">(Nielsen, 2024c; Ayers et al., 2023; Yin, Jia &amp; Wakslak, 2024)</span></p>
</section>
<section id="interfaces-usability-is-the-minimum-of-a-good-user-experience" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-usability-is-the-minimum-of-a-good-user-experience">Interfaces: Usability is the Minimum of a Good User Experience</h3>
<p>Usability sets the baseline but AI-interfaces are capable of more.</p>
<ul>
<li><p>AI UX</p></li>
<li><p>Privacy UX <span class="citation" data-cites="jarovskyYouAreProbably2022">Jarovsky (2022b)</span></p></li>
<li><p>AI UX dark patterns <span class="citation" data-cites="jarovskyDarkPatternsAI2022">Jarovsky (2022a)</span></p></li>
<li><p>AI is usually a model that spits out a number between 0 and 1, a probability score or prediction. UX is what we do with this number.</p></li>
<li><p><span class="citation" data-cites="baileyAIEducation2023">Bailey (2023)</span> believes people will increasingly use AI capabilities through UIs that are specific to a task rather than generalist interfaces like ChatGPT.</p></li>
</ul>
<p>How do the tenets of user experience (UX) apply to AI?</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>UX</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Useful</td>
</tr>
<tr class="even">
<td>Valuable</td>
</tr>
<tr class="odd">
<td>Usable</td>
</tr>
<tr class="even">
<td>Acessible</td>
</tr>
<tr class="odd">
<td>Findable</td>
</tr>
<tr class="even">
<td>Desirable</td>
</tr>
<tr class="odd">
<td>Credible</td>
</tr>
</tbody>
</table>
<p><span class="citation" data-cites="guptaDesigningAIChatbot2023">Gupta (2023)</span> proposes 3 simple goals for AI:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 26%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reduce the time to task</td>
<td>Make the task easier</td>
<td>Personalize the experience for an individual</td>
</tr>
</tbody>
</table>
<p>Usability Guidelines</p>
<p>Microsoft Co-Founder predicted in 1982 <em>“personal agents that help us get a variety of tasks”</em> <span class="citation" data-cites="billgatesBillGatesNext1982">(Bill Gates, 1982)</span> and it was Microsoft that introduced the first widely available personal assistant in 1996, called Clippy, inside the Microsoft Word software. Clippy was among the first assistants to reach mainstream adoption, helping users not yet accustomed to working on a computer, to get their bearings <span class="citation" data-cites="tashkeunemanWeLoveHate2022">(Tash Keuneman, 2022)</span>. Nonetheless, it was in many ways useless and intrusive, suggesting there was still little knowledge about UX and human-centered design. Gates never wavered though and is quoted in 2004 saying <em>“If you invent a breakthrough in artificial intelligence, so machines can learn, that is worth 10 Microsofts”</em> <span class="citation" data-cites="lohrMicrosoftDwindlingInterest2004">Lohr (2004)</span>.</p>
<p>Gates updated his ideas in 2023 focuses on the idea of <em>AI Agents</em> <span class="citation" data-cites="gatesAICompletelyChange2023">(Gates, 2023)</span>.</p>
<p>As late as in 2017, scientists were trying to create a program with enough <em>natural-language understanding</em> to extract basic facts from scientific papers <span class="citation" data-cites="stocktonIfAICan2017">Stockton (2017)</span></p>
<p>Might we try again?</p>
<p>With the advent of ChatGPT, the story of Clippy has new relevance as part of the history of AI Assistants. <span class="citation" data-cites="benjamincassidyTwistedLifeClippy2022">Benjamin Cassidy (2022)</span> and <span class="citation" data-cites="abigailcainLifeDeathMicrosoft2017">Abigail Cain (2017)</span> illustrate beautifully the story of Clippy and <span class="citation" data-cites="tashkeunemanWeLoveHate2022">Tash Keuneman (2022)</span> ask poignantly: “We love to hate Clippy — but what if Clippy was right?”</p>
<ul>
<li>Life-like speaking faces from Microsoft Research turn a single image and voice clip into a life-like representation <span class="citation" data-cites="xuVASA1LifelikeAudioDriven2024">(Xu et al., 2024)</span>.</li>
</ul>
<p>Many researchers have discussed the user experience (UX) of AI to provide <strong><em>usability guidelines</em></strong>.</p>
<p>Microsoft provides guidelines for Human-AI interaction (<span class="citation" data-cites="li2022assessing">Li et al. (2022)</span>; <span class="citation" data-cites="amershiGuidelinesHumanAIInteraction2019">Amershi et al. (2019)</span>) which provides useful heuristics categorized by context and time.</p>
<table class="caption-top table">
<caption>Microsoft’s heuristics categorized by context and time.</caption>
<thead>
<tr class="header">
<th>Context</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Initially</td>
<td></td>
</tr>
<tr class="even">
<td>During interaction</td>
<td></td>
</tr>
<tr class="odd">
<td>When wrong</td>
<td></td>
</tr>
<tr class="even">
<td>Over time</td>
<td></td>
</tr>
</tbody>
</table>
<p><span class="citation" data-cites="combiManifestoExplainabilityArtificial2022">Combi et al. (2022)</span> proposes a conceptual framework for XAI, analysis AI based on Interpretability, Understandability, Usability, and Usefulness.</p>
<ul>
<li><p><span class="citation" data-cites="zimmermanUXDesignersPushing2021">Zimmerman et al. (2021)</span> “UX designers pushing AI in the enterprise: a case for adaptive UIs”</p></li>
<li><p><span class="citation" data-cites="WhyUXShould2021">Anon (2021c)</span> “Why UX should guide AI”</p></li>
<li><p><span class="citation" data-cites="simonsterneUnlockingPowerDesign2023">Simon Sterne (2023)</span> UX is about helping the user make decisions</p></li>
<li><p><span class="citation" data-cites="davidpasztorAIUXPrinciples2018">Dávid Pásztor (2018)</span></p></li>
<li><p><span class="citation" data-cites="andersonWaysArtificialIntelligence2020">Anderson (2020)</span></p></li>
<li><p><span class="citation" data-cites="lennartziburskiUXAI2018">Lennart Ziburski (2018)</span> UX of AI</p></li>
<li><p><span class="citation" data-cites="stephaniedonaholeHowArtificialIntelligence2021">Stephanie Donahole (2021)</span></p></li>
<li><p><span class="citation" data-cites="lexowDesigningAIUX2021">Lexow (2021)</span></p></li>
<li><p><span class="citation" data-cites="davidpasztorAIUXPrinciples2018">Dávid Pásztor (2018)</span> AI UX principles</p></li>
<li><p><span class="citation" data-cites="bubeckSparksArtificialGeneral2023">Bubeck et al. (2023)</span> finds ChatGPT passes many exams meant for humans.</p></li>
<li><p><span class="citation" data-cites="suenBuildingTrustAutomatic2023">Suen &amp; Hung (2023)</span> discusses AI systems used for evaluating candidates at job interviews</p></li>
<li><p><span class="citation" data-cites="wangSyntheticNeuroscoreUsingNeuroAI2020">Wang et al. (2020)</span> propose Neuroscore to reflect perception of images.</p></li>
<li><p><span class="citation" data-cites="suArtificialIntelligenceEarly2022">Su &amp; Yang (2022)</span> and <span class="citation" data-cites="suArtificialIntelligenceAI2023">Su, Ng &amp; Chu (2023)</span> review papers on AI literacy in early childhood education and finds a lack of guidelines and teacher expertise.</p></li>
<li><p><span class="citation" data-cites="yangArtificialIntelligenceEducation2022">Yang (2022)</span> proposes a curriculum for in-context teaching of AI for kids.</p></li>
<li><p><span class="citation" data-cites="ericschmidtUXAdvancedMethod2022">Eric Schmidt &amp; Ben Herold (2022)</span> audiobook</p></li>
<li><p><span class="citation" data-cites="akshaykoreDesigningHumanCentricAI2022">Akshay Kore (2022)</span> Designing Human-Centric AI Experiences: Applied UX Design for Artificial Intelligence</p></li>
<li><p><span class="citation" data-cites="StudiesConversationalUX2018">Anon (2018)</span> chatbot book</p></li>
<li><p><span class="citation" data-cites="tomhathawayChattingHumansUser2021">Tom Hathaway &amp; Angela Hathaway (2021)</span> chatbot book</p></li>
<li><p><span class="citation" data-cites="lewAIUXWhy2020">Lew &amp; Schumacher (2020)</span> AI UX book</p></li>
<li><p>AI IXD is about human-centered seamless design</p></li>
<li><p>Storytelling</p></li>
<li><p>Human-computer interaction (HCI) has a long storied history since the early days of computing when getting a copy machine to work required specialized skill. Xerox Sparc lab focused on early human factors work and inspired a the field of HCI to make computer more human-friendly.</p></li>
<li><p><span class="citation" data-cites="soleimani10UIPatterns2018">Soleimani (2018)</span>: UI patterns for AI, new Section for Thesis background: “Human-Friendly UX For AI”?</p></li>
<li><p><strong>Discuss what is UX for AI (per prof Liou’s comment), so it’s clear this is about UX for AI</strong></p></li>
<li><p>What is Personalized AI?</p></li>
<li><p>Many large corporations have released guidelines for Human-AI interaction. <span class="citation" data-cites="mikaelerikssonbjorlingUXDesignAI">Mikael Eriksson Björling &amp; Ahmed H. Ali (n.d.)</span> Ericcson AI UX.</p></li>
<li><p>Google’s AI Principles and provides Google’s UX for AI library <span class="citation" data-cites="joshlovejoyUXAI googleOurPrinciplesGoogle">(Josh Lovejoy, n.d.; Google, n.d.)</span>. In <span class="citation" data-cites="designportlandHumansHaveFinal2018">Design Portland (2018)</span>, Lovejoy, lead UX designer at Google’s people-centric AI systems department (PAIR), reminds us that while AI offers need tools, user experience design needs to remain human-centered. While AI can find patterns and offer suggestions, humans should always have the final say.</p></li>
<li><p><span class="citation" data-cites="harvardadvancedleadershipinitiativeHumanAIInteractionArtificial2021">Harvard Advanced Leadership Initiative (2021)</span></p></li>
<li><p><span class="citation" data-cites="videolectureschannelCommunicationHumanAIInteraction2022">VideoLecturesChannel (2022)</span> “Communication in Human-AI Interaction”</p></li>
<li><p><span class="citation" data-cites="haiyizhuHumanAIInteractionFall2021">Haiyi Zhu &amp; Steven Wu (2021)</span></p></li>
<li><p><span class="citation" data-cites="akataResearchAgendaHybrid2020">Akata et al. (2020)</span></p></li>
<li><p><span class="citation" data-cites="dignumAIPeoplePlaces2021">Dignum (2021)</span></p></li>
<li><p><span class="citation" data-cites="boleizhouCVPR22Tutorial2022">Bolei Zhou (2022)</span></p></li>
<li><p><span class="citation" data-cites="readyaiHumanAIInteractionHow2020">ReadyAI (2020)</span></p></li>
<li><p><span class="citation" data-cites="vinuesaRoleArtificialIntelligence2020">Vinuesa et al. (2020)</span></p></li>
<li><p><span class="citation" data-cites="orozcoBudapestBicycleNetwork2020">Orozco et al. (2020)</span></p></li>
</ul>
</section>
<section id="interfaces-performing-under-high-stakes-situations" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-performing-under-high-stakes-situations">Interfaces: Performing Under High-Stakes Situations</h3>
<ul>
<li>The Paris Olympic games make heavy use of AI <span class="citation" data-cites="kulkarniThreeWaysAI2024">(Kulkarni, 2024)</span>.</li>
</ul>
<p>Fitness Guides, AI Guides have been shown to improve sports performance, etc, etc. Can this idea be applied to sustainability? MyFitness Pal, AI training assistant. There’s not avatar.</p>
<p>AI in Medicine, AI has been in medicine since early days with the promise to improve health outcomes.</p>
<p>Human Augmentation, Technology for augmenting human skills or replacing skills that were lost due to an accident is one usage of tech.</p>
<ul>
<li><span class="citation" data-cites="dotgoDotGo2023">(Dot Go, 2023)</span> makes the camera the interaction device for people with vision impairment.</li>
</ul>
<p>AI is being use in high–Stakes Situations (Medical, Cars, Etc).</p>
<p>AI-based systems are being implemented in medicine, where stakes are high raising the need for ethical considerations. Since CADUCEUS in the 1970s <span class="citation" data-cites="kanzaAIScientificDiscovery2021">(in Kanza et al., 2021)</span>, the first automated medical decision making system, medical AI now provides Health Diagnosic Symptoms and AI-assistants in medical imaging. <span class="citation" data-cites="calistoBreastScreeningAIEvaluatingMedical2022">(Calisto et al., 2022)</span> focuses on AI-human interactions in medical workflows and underscores the importance of output explainability. Medical professionals who were given AI results with an explanation trusted the results more. <span class="citation" data-cites="leeAIRevolutionMedicine2023">(Lee, Goldberg &amp; Kohane, 2023)</span> imagines an AI revolution in medicine using GPT models, providing improved tools for decreasing the time and money spent on administrative paperwork while providing a support system for analyzing medical data.</p>
<ul>
<li>Example of ChatGPT explaining medical terminology in a blood report.</li>
</ul>
<ul>
<li><p><span class="citation" data-cites="singhalExpertLevelMedicalQuestion2023">Singhal et al. (2023)</span> medial AI reaching expert-level question-answering ability.</p></li>
<li><p><span class="citation" data-cites="ayersComparingPhysicianArtificial2023">Ayers et al. (2023)</span> in an online text-based setting, patients rated answers from the AI better, and more empathetic, than answers from human doctors.</p></li>
<li><p><span class="citation" data-cites="daisywolfWhereWillAI2023">Daisy Wolf &amp; Pande Vijay (2023)</span> criticizes US healthcare’s slow adoption of technology and predicts AI will help healthcare leapfrog into a new era of productivity by acting more like a human assistant.</p></li>
<li><p><span class="citation" data-cites="elizastricklandDrChatGPTWill2023">Eliza Strickland (2023)</span> Chat interface for medical communication</p></li>
<li><p><span class="citation" data-cites="jeblickChatGPTMakesMedicine2022">Jeblick et al. (2022)</span> suggest complicated radiology reports can be explained to patients using AI chatbots.</p></li>
<li><p><span class="citation" data-cites="HealthPoweredAda">Anon (n.d.e)</span> health app, “Know and track your symptoms”</p></li>
<li><p><span class="citation" data-cites="BuoyHealthCheck">Anon (n.d.a)</span> AI symptom checker,</p></li>
<li><p><span class="citation" data-cites="womeninaiHowCanAI">Women in AI (n.d.)</span> AI-based health monitoring</p></li>
<li><p><span class="citation" data-cites="HomeLarkHealth">Anon (n.d.f)</span> track chronic condition with AI-chat</p></li>
<li><p><span class="citation" data-cites="stephaniedonaholeHowArtificialIntelligence2021">Stephanie Donahole (2021)</span> AI impact on UX design</p></li>
<li><p><span class="citation" data-cites="yuanSocialAnxietyModerator2022">Yuan, Zhang &amp; Wang (2022)</span>: “AI assistant advantages are important factors affecting the <em>utilitarian/hedonic</em> value perceived by users, which further influence user willingness to accept AI assistants. The relationships between AI assistant advantages and utilitarian and hedonic value are affected differently by social anxiety.”</p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Name</th>
<th>Features</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Charisma</td>
<td></td>
</tr>
<tr class="even">
<td>Replika</td>
<td>Avatar, Emotion, Video Call, Audio</td>
</tr>
<tr class="odd">
<td>Siri</td>
<td>Audio</td>
</tr>
</tbody>
</table>
</section>
<section id="interfaces-human-computer-interactions-without-the-computer" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-human-computer-interactions-without-the-computer">Interfaces: Human-Computer Interactions Without the “Computer”</h3>
<p>AI Affects Human-Computer Interactions</p>
<p>The field of Human Factors and Ergonomics (HFE) emphasizes designing user experiences (UX) that cater to human needs <span class="citation" data-cites="theinternationalergonomicsassociationHumanFactorsErgonomics2019">(The International Ergonomics Association, 2019)</span>. Designers think through every interaction of the user with a system and consider a set of metrics at each point of interaction including the user’s context of use and emotional needs.</p>
<p>Software designers, unlike industrial designers, can’t physically alter the ergonomics of a device, which should be optimized for human well-being to begin with and form a cohesive experience together with the software. However, software designers can significantly reduce mental strain by crafting easy-to-use software and user-friendly user journeys. Software interaction design goes beyond the form-factor and accounts for human needs by using responsive design on the screen, aural feedback cues in sound design, and even more crucially, by showing the relevant content at the right time, making a profound difference to the experience, keeping the user engaged and returning for more. In the words of <span class="citation" data-cites="babichInteractionDesignVs2019">(Babich, 2019)</span>, <strong><em>“</em></strong>[T]he moment of interaction is just a part of the journey that a user goes through when they interact with a product. User experience design accounts for all user-facing aspects of a product or system”.</p>
<p>Drawing a parallel from narrative studies terminology, we can view user interaction as a heroic journey of the user to achieve their goals, by navigating through the interface until a success state - or facing failure. Storytelling has its part in interface design however designing for transparency is just as important, when we’re dealing with the user’s finances and sustainability data, which need to be communicated clearly and accurately, to build long-term trust in the service. For a sustainable investment service, getting to a state of success - or failure - may take years, and even longer. Given such long timeframes, how can the app provide support to the user’s emotional and practical needs throughout the journey?</p>
<p><span class="citation" data-cites="tubikstudioUXDesignGlossary2018">(Tubik Studio, 2018)</span> argues <em>affordance</em> measures the clarity of the interface to take action in user experience design, rooted in human visual perception, however, affected by knowledge of the world around us. A famous example is the door handle - by way of acculturation, most of us would immediately know how to use it - however, would that be the case for someone who saw a door handle for the first time? A similar situation is happening to the people born today. Think of all the technologies they have not seen before - what will be the interface they feel the most comfortable with?</p>
<p>For the vast majority of this study’s target audience (college students), social media can be assumed as the primary interface through which they experience daily life. The widespread availability of mobile devices, cheap internet access, and AI-based optimizations for user retention, implemented by social media companies, means this is the baseline for young adult users’ expectations (as of writing in 2020).</p>
<p><span class="citation" data-cites="shinUserExperienceWhat2020">(Shin, Zhong &amp; Biocca, 2020)</span> proposes the model (fig.&nbsp;10) of Algorithmic Experience (AX) <em><strong>“</strong>investigating the nature and processes through which users perceive and actualize the potential for algorithmic affordance”</em> highlighting how interaction design is increasingly becoming dependent on AI. The user interface might remain the same in terms of architecture, but the content is improved, based on personalization and understanding the user at a deeper level.</p>
<p>In 2020 (when I proposed this thesis topic), Google had recently launched an improved natural language engine to better understand search queries <span class="citation" data-cites="UnderstandingSearchesBetter2019">(Anon, 2019)</span>, which was considered the next step towards <em>understanding</em> human language semantics. The trend was clear, and different types of algorithms were already involved in many types of interaction design, however, we were in the early stages of this technology (and still are <em>early</em> in 2024). Today’s ChatGPT, Claude and Gemini have no problem understanding human semantics - yet are they intelligent?</p>
<p>Intelligence may be besides the point as long as AI <em>becomes very good at reasoning</em>. AI is a <em>reasoning engine</em> <span class="citation" data-cites="shipperGPT4ReasoningEngine2023 bubeckSparksArtificialGeneral2023 baileyAIEducation2023">(Shipper, 2023; Bubeck et al., 2023; see Bailey, 2023 for a summary)</span>. That general observation applies to voice recognition, voice generation, natural language parsing, among others. Large consumer companies like McDonald’s are in the process of replacing human staff with AI assistants in the drive-through, which can do a better job in providing a personal service than human clerks, for whom it would be impossible to remember the information of thousands of clients. In <span class="citation" data-cites="barrettMcDonaldAcquiresMachineLearning2019">(Barrett, 2019)</span>, in the words of <em>Easterbrook</em>, a previous CEO of McDonald’s <em>“How do you transition from mass marketing to mass personalization?”</em></p>
</section>
<section id="interfaces-do-ai-agents-need-anthropomorphism" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-do-ai-agents-need-anthropomorphism">Interfaces: Do AI-Agents Need Anthropomorphism</h3>
<p>What are the next features that could improve the next-generation UX/UI of AI-based assistants?</p>
<ul>
<li>GPT 4o combines different abilities into the same model, preserving more information: <span class="citation" data-cites="openaiHelloGPT4o2024">(OpenAI, 2024b)</span>.</li>
</ul>
<p><span class="citation" data-cites="skipperHowAIChanging2022">(Stone Skipper, 2022)</span> sketches a vision of <em>“[AI] blend into our lives in a form of apps and services”</em> deeply ingrained into daily human activity.</p>
<p>Should AIs look anthropomorphic or fade in the background? It’s an open question. Perhaps we can expect a mix of both depending on the context of use and goals of the particular AI.</p>
<p><span class="citation" data-cites="aschenbrennerSITUATIONALAWARENESSDecade2024">(Aschenbrenner, 2024)</span> predicts “drop-in virtual coworkers”, AI-agents who are able to use computer systems like a human seamlessly replacing human employees.</p>
<table class="caption-top table">
<caption>Some notable examples of anthropomorphic AIs for human emotions.</caption>
<colgroup>
<col style="width: 36%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th>Anthropomorphic AI User Interfaces</th>
<th>Non-Anthropomorphic AI User Interfaces</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AI wife <span class="citation" data-cites="MyWifeDead2023">(Anon, 2023e)</span></td>
<td>Generative AI has enabled developers to create AI tools for several industries, including AI-driven website builders <span class="citation" data-cites="constandseHowAIdrivenWebsite2018">(Constandse, 2018)</span></td>
</tr>
<tr class="even">
<td><span class="citation" data-cites="sarahperezCharacterAIA16zbacked2023">(Sarah Perez, 2023)</span> character AI</td>
<td>AI tools for web designers <span class="citation" data-cites="patrizia-slongoAIpoweredToolsWeb2020">(patrizia-slongo, 2020)</span></td>
</tr>
<tr class="odd">
<td>Mourning for the ‘dead’ AI <span class="citation" data-cites="phoebearslanagic-wakefieldReplikaUsersMourn">(Phoebe Arslanagić-Wakefield, n.d.)</span></td>
<td>Microsoft Designer allows generating UIs just based on a text prompt <span class="citation" data-cites="microsoftMicrosoftDesignerStunning2023">(Microsoft, 2023)</span></td>
</tr>
<tr class="even">
<td>AI for therapy <span class="citation" data-cites="broderickPeopleAreUsing2023">(Broderick, 2023)</span></td>
<td>personalized bed-time stories for kids generated by AI <span class="citation" data-cites="bedtimestory.aiAIPoweredStory2023">(Bedtimestory.ai, 2023)</span></td>
</tr>
<tr class="odd">
<td>Mental health uses: AI for bullying <span class="citation" data-cites="sungParentsWorryTeens2023">(Sung, 2023)</span></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><span class="citation" data-cites="costaInteractionDesignAI2022">(Costa &amp; Silva, 2022)</span> “Interaction Design for AI Systems”</li>
</ul>
</section>
<section id="acceptance-mediated-experiences-set-user-expectations" class="level3">
<h3 class="anchored" data-anchor-id="acceptance-mediated-experiences-set-user-expectations">Acceptance: Mediated Experiences Set User Expectations</h3>
<p>How AIs are represented in popular media shapes the way we think about AI companions. Some stories have AIs both in positive and negative roles, such as Star Trek and Knight Rider. In some cases like Her and Ex Machina, the characters may be complex and ambivalent rather than fitting into a simple positive or negative box. In Isaac Asimov’s books, the AIs (mostly in robot form) struggle with the 3 laws of robotics, raising thought-provoking questions.</p>
<p>AI Assistants in Media Portrayals mostly have some level of anthropomorphism through voice or image to be able to film; indeed, a purely text-based representation may be too boring an un-cinematic.</p>
<p>There have been dozens of AI-characters in the movies, TV-series, games, and (comic) books. In most cases, they have a physical presence or a voice, so they could be visible for the viewers. Some include KITT (Knight Industries Two Thousand).</p>
<table class="caption-top table">
<caption>AIs in different forms of media.</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Movie / Series / Game / Book</th>
<th>Character</th>
<th>Positive</th>
<th>Ambivalent</th>
<th>Negative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2001: A Space Odyssey</td>
<td>HAL 9000</td>
<td></td>
<td></td>
<td>X</td>
</tr>
<tr class="even">
<td>Her</td>
<td>Samantha</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Alien</td>
<td>MU/TH/UR 6000 (Mother)</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Terminator</td>
<td>Skynet</td>
<td></td>
<td></td>
<td>X</td>
</tr>
<tr class="odd">
<td>Summer Wars</td>
<td>Love Machine</td>
<td></td>
<td></td>
<td>X</td>
</tr>
<tr class="even">
<td>Marvel Cinematic Universe</td>
<td>Jarvis, Friday</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Knight Rider</td>
<td>KITT</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>CARR</td>
<td></td>
<td></td>
<td>X</td>
</tr>
<tr class="odd">
<td>Star Trek</td>
<td>Data</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Lore</td>
<td></td>
<td></td>
<td>X</td>
</tr>
<tr class="odd">
<td>Ex Machina</td>
<td>Kyoko</td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Ava</td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr class="odd">
<td>Tron</td>
<td>Tron</td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr class="even">
<td>Neuromancer</td>
<td>Wintermute</td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr class="odd">
<td>The Caves of Steel / Naked Sun</td>
<td>R. Daneel Olivaw</td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr class="even">
<td>The Robots of Dawn</td>
<td>R. Giskard Reventlov</td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr class="odd">
<td>Portal</td>
<td>GLaDOS</td>
<td></td>
<td></td>
<td>X</td>
</tr>
</tbody>
</table>
<div id="758443cc" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>scifi_chart()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ai_files/figure-html/cell-6-output-1.png" width="1305" height="933" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="acceptance-roleplay-fits-computers-into-social-contexts" class="level3">
<h3 class="anchored" data-anchor-id="acceptance-roleplay-fits-computers-into-social-contexts">Acceptance: Roleplay Fits Computers Into Social Contexts</h3>
<p>Should AIs be required to disclose they are AIs?</p>
<p>AI Friends and Roleplay (Anthropomorphic)</p>
<p>Calling a machine a friend is a proposal bound to turn heads. But if we take a step back and think about how children have been playing with toys since before we have records of history. It’s very common for children to imagine stories and characters in play - it’s a way to develop one’s imagination <strong><em>learn through roleplay</em></strong>. A child might have toys with human names and an imaginary friend and it all seems very normal. Indeed, if a child doesn’t like to play with toys, we might think something is wrong.</p>
<p>Likewise, inanimate objects with human form have had a role to play for adults too. Anthropomorphic paddle dolls have been found from Egyptian tombs dated 2000 years B.C. <span class="citation" data-cites="PaddleDollMiddle2023">Anon (2023g)</span>: We don’t know if these dolls were for religious purposes, for play, or for something else, yet their burial with the body underlines their importance.</p>
<p>Coming back closer to our own time, Barbie dolls are popular since their release in 1959 till today. Throughout the years, the doll would follow changing social norms, but retain in human figure. In the 1990s, a Tamagotchi is perhaps not a human-like friend but an animal-like friend, who can interact in limited ways.</p>
<p>How are conversational AIs different from dolls? They can respond coherently and perhaps that’s the issue - they are too much like humans in their communication. We have crossed the <strong><em>Uncanny Valley</em></strong> (where the computer-generated is nearly human and thus unsettling) to a place where is really hard to tell a difference. And if that’s the case, are we still playing?</p>
<p>Should the AI play a human, animal, or robot? Anthropomorphism can have its drawbacks; humans have certain biases and preconceptions that can affect human-computer interactions <span class="citation" data-cites="pilacinskiRobotEyesDon2023">(Pilacinski et al., 2023)</span> reports humans were less likely to collaborate with red-eyed robots.</p>
<p>The AI startups like Inworld and Character.AI have raised large rounds of funding to create characters, which can be plugged in into online worlds, and more importantly, remember key facts about the player, such as their likes and dislikes, to generate more natural-sounding dialogues <span class="citation" data-cites="wiggersInworldGenerativeAI2023">Wiggers (2023)</span></p>
<ul>
<li><span class="citation" data-cites="lenharoChatGPTGivesExtra2023">Lenharo (2023)</span> experimental study reports AI productivity gains, DALL-E and ChatGPT are qualitatively better than former automation systems.</li>
</ul>
<p><strong>Human-like</strong></p>
<p>Is anthropomorphism necessary? (Savings literature says it is)</p>
<p>As AIs became more expressive and able to to <strong>roleplay</strong>, we can begin discussing some human-centric concepts and how people relate to other people. AI companions, AI partners, AI assistants, AI trainers - there’s are many <strong>roles</strong> for the automated systems that help humans in many activities, powered by artificial intelligence models and algorithms.</p>
<ul>
<li><p>RQ: Do college students prefer to talk to an Assistant, Friend, Companion, Coach, Trainer, or some other Role?</p></li>
<li><p>RQ: Are animal-like, human-like or machine-like AI companions more palatable to college students?</p></li>
</ul>
<p>Humans (want to) see machines as human [ADD CITATION]</p>
<p>If we see the AI as being in human service. <span class="citation" data-cites="davidjohnstonSmartAgentProtocol2023">David Johnston (2023)</span> proposes <strong><em>Smart Agents</em></strong>, “general purpose AI that acts according to the goals of an individual human”. AI agents can enable <strong><em>Intention Economy</em></strong> where one simply describes one’s needs and a complex orchestration of services ensues, managed by the the AI, in order to fulfill human needs <span class="citation" data-cites="searlsIntentionEconomyWhen2012">Searls (2012)</span>. AI assistants provide help at scale with little to no human intervention in a variety of fields from finance to healthcare to logistics to customer support.</p>
<p>There is also the question of who takes responsibility for the actions take by the AI agent. “Organization research suggests that acting through human agents (i.e., the problem of indirect agency) can undermine ethical forecasting such that actors believe they are acting ethically, yet a) show less benevolence for the recipients of their power, b) receive less blame for ethical lapses, and c) anticipate less retribution for unethical behavior.” <span class="citation" data-cites="gratchPowerHarmAI2022">Gratch &amp; Fast (2022)</span></p>
<ul>
<li>Anthropomorphism literature <span class="citation" data-cites="liAnthropomorphismBringsUs2021">Li &amp; Sung (2021)</span> “high-anthropomorphism (vs.&nbsp;low-anthropomorphism) condition, participants had more positive attitudes toward the AI assistant, and the effect was mediated by psychological distance. Though several studies have demonstrated the effect of anthropomorphism, few have probed the underlying mechanism of anthropomorphism thoroughly”</li>
<li><span class="citation" data-cites="erikbrynjolfssonTuringTrapPromise2022">Erik Brynjolfsson (2022)</span> “The Turing Trap: The Promise &amp; Peril ofHuman-Like Artificial Intelligence”</li>
<li><span class="citation" data-cites="xuWeSeeMachines2018">Xu &amp; Sar (2018)</span> “Do We See Machines TheSame Way As We See Humans? A Survey On Mind Perception Of Machines AndHuman Beings”</li>
<li><span class="citation" data-cites="martinez-plumedFuturesArtificialIntelligence2021">Martínez-Plumed, Gómez &amp; Hernández-Orallo (2021)</span> envisions the future of AI “Futures of artificial intelligence through technology readiness levels”</li>
<li>The number of AI-powered assistants is too large to list here. I’ve chosen a few select examples in the table below.</li>
</ul>
<p><strong>Animal-like: Some have an avatar, some not. I’ve created a framework for categorization. Human-like or not… etc</strong></p>
<p><strong>Machine-like</strong></p>
<p>The Oxford Internet Institute defines AI simply as <strong><em>“computer programming that learns and adapts”</em></strong> <span class="citation" data-cites="googleAZAI2022">Google &amp; The Oxford Internet Institute (2022)</span>. Google started using AI in 2001, when a simple machine learning model improved spelling mistakes while searching; now in 2023 most of Google’s products are are based on AI <span class="citation" data-cites="googleGooglePresentsAI2022">Google (2022)</span>. Throughout Google’s services, AI is hidden and calls no attention itself. It’s simply the complex system working behind the scenes to delivery a result in a barebones interface.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 41%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Product</th>
<th>Link</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Github CoPilot</td>
<td>personal.ai</td>
<td>AI helper for coding</td>
</tr>
<tr class="even">
<td>Google Translate</td>
<td>translate.google.com</td>
<td></td>
</tr>
<tr class="odd">
<td>Google Search</td>
<td>google.com</td>
<td></td>
</tr>
<tr class="even">
<td>Google Interview Warmup</td>
<td>grow.google/certificates/interview-warmup</td>
<td>AI training tool</td>
</tr>
<tr class="odd">
<td>Perplexity</td>
<td><span class="citation" data-cites="hinesPerplexityAnnouncesAI2023">Hines (2023b)</span></td>
<td>perplexity.ai chat-based search</td>
</tr>
</tbody>
</table>
<p>Everything that existed before OpenAI’s GPT 4 has been blown out of the water.</p>
<p>Pre-2023 literature is somewhat limited when it comes to AI companions as the advantage of LLMs has significantly raised the bar for AI-advisor abilities as well as user expectations.</p>
<p>Some evergreen advice most relates to human psychology which has remained the same. <span class="citation" data-cites="haugelandUnderstandingUserExperience2022">(Haugeland et al., 2022)</span> discusses <strong><em>hedonic user experience</em></strong> in chatbots and <span class="citation" data-cites="stephhayEnoFinancialAI2017">(Steph Hay, 2017)</span> explains the relationship between emotions and financial AI.</p>
<ul>
<li><p><span class="citation" data-cites="eugeniakuydaReplika2023">Eugenia Kuyda (2023)</span> Conversational AI - Replika</p></li>
<li><p><span class="citation" data-cites="greylockOpenAICEOSam2022">Greylock (2022)</span> Natural language chatbots such as ChatGPT</p></li>
<li><p><span class="citation" data-cites="nathanbenaichStateAIReport2022">Nathan Benaich &amp; Ian Hogarth (2022)</span> State of AI Report</p></li>
<li><p><span class="citation" data-cites="qorusGreatReinventionGlobal2023">Qorus (2023)</span> Digital banking revolution</p></li>
<li><p><span class="citation" data-cites="lowerChatbotsTooGood2017">Lower (2017)</span> “Chatbots: Too Good to Be True? (They Are, Here’sWhy).”</p></li>
<li><p><span class="citation" data-cites="isabellaghassemismithInterviewDanielBaeriswyl2019">Isabella Ghassemi Smith (2019)</span></p></li>
<li><p><span class="citation" data-cites="josephinewaktareheintzCleo">Josephine Wäktare Heintz (n.d.)</span> Cleo copywriter</p></li>
<li><p>Smaller startups have created digital companions such as Replika (fig.&nbsp;8), which aims to become your friend, by asking probing questions, telling jokes, and learning about your personality and preferences - to generate more natural-sounding conversations.</p></li>
</ul>
</section>
<section id="interfaces-roleplay-for-financial-robo-advisors" class="level3">
<h3 class="anchored" data-anchor-id="interfaces-roleplay-for-financial-robo-advisors">Interfaces: Roleplay for Financial Robo-Advisors</h3>
<p><em>Robo-advisors</em> is a fintech term that was in fashion largely before the arrival of AI assistants and has been thus superseded by newer technologies. Ideally, robo-advisors can be more dynamic than humans and respond to changes to quickly and cheaply. Human advisors are very expensive and not affordable for most consumers. <span class="citation" data-cites="capponiPersonalizedRoboAdvisingInteractive2019">(Capponi, Ólafsson &amp; Zariphopoulou, 2019)</span> argues <em>“The client has a risk profile that varies with time and to which the robo-advisor’s investment performance criterion dynamically adapts”</em>. The key improvement of <em>personalized financial advice</em> is understanding the user’s <em>dynamic risk profile</em>.</p>
<ul>
<li>Newer literature notes robo-advisor related research is scattered across disciplines <span class="citation" data-cites="zhuImplementingArtificialIntelligence2024">(Zhu, Vigren &amp; Söderberg, 2024)</span>. – Athropomorphism: human-like attributes in robo-advisors, such as conversational chatbots, can affect adoption and risk preferences among customers. Studies show that anthropomorphized robo-advisors increase customer trust and reduce algorithm aversion.” <strong>similar to my research</strong></li>
</ul>
<p>In the early days in Europe, Germany and the United Kingdom led the way with the most robo-advisory usage <span class="citation" data-cites="cowanRoboAdvisersStart2018">(Cowan, 2018)</span>. While Germany had 30+ robot-advisors on the market in 2019, with a total of 3.9 billion EUR under robotic management, it was far less than individual apps like Betterment managed in the US <span class="citation" data-cites="bankinghubRoboAdvisorNew2019">(Bankinghub, 2019)</span>. Already in 2017, several of the early robo-advisors apps have shut down in the UK <span class="citation" data-cites="altfiETFmaticAppDownloaded2017">(AltFi, 2017)</span>. ETFmatic gained the largest number of downloads by 2017, focusing exclusively on exchange-traded funds (ETFs), tracking stock-market indexes automatically, with much less sophistication, than their US counterparts <span class="citation" data-cites="altfiETFmaticAppDownloaded2017">(AltFi, 2017)</span>. The app was bought by a bank in 2021 and closed down in 2023 <span class="citation" data-cites="altfiBelgiumAionBank2021 silvaETFmaticReview2023 ETFmaticAccountFunding2023">(AltFi, 2021; Silva, 2023; Anon, 2023b)</span>.</p>
<p>Some relevant papers include a comparison of robot advisors by <span class="citation" data-cites="barbarafriedbergM1FinanceVs2021">(Barbara Friedberg, 2021)</span> and <span class="citation" data-cites="slackAturaProcess2021">(Slack, 2021)</span>’s account of how before Generative AI, financial chatbots were developed manually using a painstaking process that was slow and error-prone, for example using the Atura Process. Older financial robo-advisors, built by fintech companies aiming to provide personalized suggestions for making investments such as Betterment and Wealthfront are forced to upgrade their technology to keep up.</p>
<p>The user interface and user experience (UI/UX) of consumer-focused investing apps in Europe has improved a over the past decade. The changing landscape is related to the earlier availability of better quality apps available in the US and the disappearance of the 1st generation of rudimentary investing apps and the lessons learned on how to automate the delivery of financial services while increasing user satisfaction.</p>
<p>In India, research is being conducted on how AI advisors could assist with investors’ erratic behavior in stock market volatility situations, albeit without much success <span class="citation" data-cites="bhatiaRoboAdvisoryIts2020">(Bhatia, Chandani &amp; Chhateja, 2020)</span>. India had more than 2000 fintechs since 2015 <span class="citation" data-cites="migozziYouShouldWhat2023">(Migozzi, Urban &amp; Wójcik, 2023)</span>.</p>
<ul>
<li><p><span class="citation" data-cites="neuralnineFinancialAIAssistant2021">NeuralNine (2021)</span> Financial AI assistant in Python</p></li>
<li><p><span class="citation" data-cites="davidExplainableAIAdoption2021">David, Resheff &amp; Tron (2021)</span> Can explainable AI help adoption of Financial AI assistants?</p></li>
<li><p><span class="citation" data-cites="brownHowFinancialChatbots2021">Brown (2021)</span> Financial chatbots</p></li>
<li><p>Robo-advisors compete with community investing such as hedge funds, mutual funds, copy-trading, and DAOs with treasuries. Robo-Advisor do not have the type of social proof a community-based investment vehicle has. The question is, does the user trust the robot or a human.</p></li>
<li><p>While the financial AI companion apps in the US market are ahead globally, they are not yet using many of the user experience innovations that are prevalent on social media platforms targeted at Generation Z and/or Millennials, possibly presenting an opportunity for cross-industry knowledge transfer, from businesses that are traditionally closer to the consumer - such as retailers. Financial AI companion apps have not yet grown to mainstream scale in Asia, Africa, Latin America, and Europe, being for the moment a largely US-based retail investor trend. The apps outside of the US are niche products in a nascent stage, however, they still provide relevant design directions or stories of what to avoid.</p></li>
<li><p><span class="citation" data-cites="WhyDesignKey2021">Anon (2021b)</span></p></li>
<li><p><span class="citation" data-cites="seanmcgowanUXDesignFinTech2018">Sean McGowan (2018)</span></p></li>
<li><p><span class="citation" data-cites="robindhanwaniFintechUIUX2021">ROBIN DHANWANI (2021)</span></p></li>
<li><p><span class="citation" data-cites="DesigningFintechApp2021">Anon (2021a)</span></p></li>
<li><p><span class="citation" data-cites="cordeiroDesignNoLonger2016">Cordeiro &amp; Weevers (2016)</span></p></li>
<li><p><span class="citation" data-cites="ungrammaryProductDesignCase2020">Ungrammary (2020)</span></p></li>
<li><p>Raha maraton etv investeerimissaade.. raadios on ka mingi saade</p></li>
<li><p><span class="citation" data-cites="EmpoweringDigitalAsset">Anon (n.d.c)</span>: digital assets bank</p></li>
<li><p><span class="citation" data-cites="MyclimateYourPartner2023">Anon (2023f)</span> calculate climate cost</p></li>
<li><p><span class="citation" data-cites="GreenCentralBanking">Anon (n.d.d)</span></p></li>
<li><p><span class="citation" data-cites="hydeGiftHowCreative2006">Hyde (2006)</span> Money as a gift</p></li>
<li><p><span class="citation" data-cites="johnssenkeeziVeBeenInvited2022">John Ssenkeezi (2022)</span>: Small stock investments</p></li>
<li><p>Financial empowerment</p></li>
<li><p>Small cash apps like African market Investment Clubs Invest in sustainability with people smarter than myself</p></li>
<li><p><span class="citation" data-cites="PhaseTwoInvesting">Anon (n.d.i)</span></p></li>
<li><p><span class="citation" data-cites="qayyumrajanESGAnalyticsIntroduction2021">Qayyum Rajan (2021)</span> ESG pulse</p></li>
<li><p><span class="citation" data-cites="NGFS">Anon (n.d.h)</span> Network for Greening the Financial System</p></li>
<li><p><span class="citation" data-cites="smartwealthHowBecomeInvestor2021">SmartWealth (2021)</span> How do consumer become investors? marketing materials say: “One of the greatest hurdles to financial independence is a consumer mindset.” One of the greatest hurdles to sustainability is a consumer mindset?</p></li>
<li><p><span class="citation" data-cites="outlawTurnYourCustomers2015">Outlaw (2015)</span></p></li>
<li><p><span class="citation" data-cites="malliarisUsingNeuralNetworks1996">Malliaris &amp; Salchenberger (1996)</span> <strong>(Need to pay for paper!)</strong></p></li>
<li><p><span class="citation" data-cites="CMBNewFuture">Anon (n.d.b)</span> Huawei</p></li>
<li><p><span class="citation" data-cites="Vise2023">Anon (2023i)</span> Personalised portfolios</p></li>
<li><p><span class="citation" data-cites="WalletAppsGoogle">Anon (n.d.g)</span> Thai finance app</p></li>
<li><p><span class="citation" data-cites="ThaiFintechAssociation">Anon (n.d.j)</span></p></li>
<li><p><span class="citation" data-cites="renatocapeljMobileHedgeFund2021">Renato Capelj (February 16, 2021 6:47 PM)</span></p></li>
</ul>
</section>
</section>
<section id="design-implications" class="level2">
<h2 class="anchored" data-anchor-id="design-implications">Design Implications</h2>
<p>This chapter looked at AI in general since its early history and then focused on AI assistants in particular.</p>
<table class="caption-top table">
<caption>Design implications arising from this chapter.</caption>
<colgroup>
<col style="width: 36%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th>Category</th>
<th>Implication</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Voice Assistants</td>
<td>There are many distinct ways how an algorithm can communicate with a human. From a simple search box such as Google’s to chatbots, voices, avatars, videos, to full physical manifestation, there are interfaces to make it easier for the human communicate with a machine.</td>
</tr>
<tr class="even">
<td>Sustainability</td>
<td>While I’m supportive of the idea of using AI assistants to highlight more sustainable choices, I’m critical of the tendency of the above examples to shift full environmental responsibility to the consumer. Sustainability is a complex interaction, where the producers’ conduct can be measured and businesses can bear responsibility for their processes, even if there’s market demand for polluting products.</td>
</tr>
<tr class="odd">
<td>Sustainability</td>
<td>Personal sustainability projects haven’t so far achieved widespread adoption, making the endeavor to influence human behaviors towards sustainability with just an app - like its commonplace for health and sports activity trackers such as Strava (fig.&nbsp;9) -, seem unlikely. Personal notifications and chat messages are not enough unless they provide the right motivation. Could visualizing a connection to a larger system, showing the impact of the eco-friendly actions taken by the user, provide a meaningful motivation to the user, and a strong signal to the businesses?</td>
</tr>
<tr class="even">
<td>Machine Learning</td>
<td>All of the interfaces mentioned above make use of machine learning (ML), a tool in the AI programming paradigm for finding patterns in large sets of data, which enables making predictions useful in various contexts, including financial decisions. These software innovations enable new user experiences, providing an interactive experience through chat (chatbots), using voice generation (voice assistants), virtual avatars (adds a visual face to the robot).</td>
</tr>
<tr class="odd">
<td>Character Design</td>
<td>I’m a digital companion, a partner, an assistant. I’m a Replika.” said Replika, a digital companion app via Github CO Pilot, another digital assistant for writing code, is also an example of how AI can be used to help us in our daily lives.</td>
</tr>
<tr class="even">
<td>Psychology</td>
<td>Humans respond better to humans?</td>
</tr>
<tr class="odd">
<td>Psychology</td>
<td>Humans respond better to machines that into account emotion?</td>
</tr>
<tr class="even">
<td>Open Source</td>
<td>For public discussion to be possible on how content is displayed, sorted, and hidden, algorithms need to be open source.</td>
</tr>
<tr class="odd">
<td>User Experience</td>
<td>User experience design (AI UX) plays a crucial role in improving the consumer to investing journey. The missed opportunity to provide an even more interactive experience in line with user expectations.</td>
</tr>
<tr class="even">
<td>LLMs</td>
<td>Prompt engineering findings have significance for “green filter” as it validates the idea of creating advanced prompts for improved responses. For “green filter”, the input would consist of detailed user data + sustainability data for detailed analysis.</td>
</tr>
<tr class="odd">
<td>Cuteness</td>
<td>Cuter apps have higher retention</td>
</tr>
<tr class="even">
<td>Transparency</td>
<td>Understanding algorithm transparency helps humans to regard the AI as a machine rather than a human</td>
</tr>
<tr class="odd">
<td>Anthropomorphism</td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="feature-ideas" class="level2">
<h2 class="anchored" data-anchor-id="feature-ideas">Feature Ideas</h2>
<table class="caption-top table">
<tbody>
<tr class="odd">
<td></td>
<td>Plap</td>
</tr>
</tbody>
</table>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>